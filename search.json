[
  {
    "objectID": "slide.html",
    "href": "slide.html",
    "title": "What is formalization",
    "section": "",
    "text": "ambiguity in natural language\n\nimplicit assumptions\nskipping details: “It’s clear that we have…”\n“viewed as” arguments: \\(V^{**} = V\\), \\((A \\times B) \\times C = A \\times (B \\times C)\\) 1\nabuses of notation: \\(3 \\in \\mathbb Z / 5 \\mathbb Z\\), \\(\\mathbb C \\subseteq \\mathbb C[x]\\)\n\nprecision in formal language\n\ncomputer programs are formal languages\n\n\n1 Knowledgable audience may recognize them as examples of natural isomorphisms in category theory.",
    "crumbs": [
      "Introduction to Formal Mathematics with Lean 4"
    ]
  },
  {
    "objectID": "slide.html#natural-language-vs.-formal-language",
    "href": "slide.html#natural-language-vs.-formal-language",
    "title": "What is formalization",
    "section": "",
    "text": "ambiguity in natural language\n\nimplicit assumptions\nskipping details: “It’s clear that we have…”\n“viewed as” arguments: \\(V^{**} = V\\), \\((A \\times B) \\times C = A \\times (B \\times C)\\) 1\nabuses of notation: \\(3 \\in \\mathbb Z / 5 \\mathbb Z\\), \\(\\mathbb C \\subseteq \\mathbb C[x]\\)\n\nprecision in formal language\n\ncomputer programs are formal languages\n\n\n1 Knowledgable audience may recognize them as examples of natural isomorphisms in category theory.",
    "crumbs": [
      "Introduction to Formal Mathematics with Lean 4"
    ]
  },
  {
    "objectID": "slide.html#mathematical-proofs-vs.-computer-programs",
    "href": "slide.html#mathematical-proofs-vs.-computer-programs",
    "title": "What is formalization",
    "section": "Mathematical proofs vs. Computer programs2",
    "text": "Mathematical proofs vs. Computer programs2\n\nCurry–Howard correspondence\n\n\nLogic\nProgramming\n\n\n\n\nproposition\ntype\n\n\nproof\nterm\n\n\nproposition is true\ntype has a term\n\n\nproposition is false\ntype doesn’t have a term\n\n\nlogical constant TRUE\nunit type\n\n\nlogical constant FALSE\nempty type\n\n\nimplication \\(\\to\\)\nfunction type\n\n\nconjunction \\(\\land\\)\nproduct type \\(\\prod\\)\n\n\ndisjunction \\(\\lor\\)\nsum type \\(\\sum\\)\n\n\nuniversal quantification \\(\\forall\\)\ndependent product type \\(\\prod\\)\n\n\nexistential quantification \\(\\exists\\)\ndependent sum type \\(\\sum\\)",
    "crumbs": [
      "Introduction to Formal Mathematics with Lean 4"
    ]
  },
  {
    "objectID": "slide.html#set-theory-vs.-type-theory",
    "href": "slide.html#set-theory-vs.-type-theory",
    "title": "What is formalization",
    "section": "Set theory vs. Type theory",
    "text": "Set theory vs. Type theory\n\nMathematicians choose axiomatic set theory (with first-order logic) as the foundation of mathematics.\n\nnaive set theory fits human’s intuition well\n\nType theory is an alternative foundation that is equally expressive, but more suitable for computer formalization.\n\n\n\n\nSet Theory\nType Theory\n\n\n\n\neverything is a set\neverything has a type\n\n\n\\(3 \\in \\mathbb R\\) is a proposition\n\\((3 : \\mathbb R)\\) is a typing judgment\n\n\n\\(\\mathbb Q \\subseteq \\mathbb R\\) is an inclusion\n\\(\\mathbb Q \\to \\mathbb R\\) is a type conversion",
    "crumbs": [
      "Introduction to Formal Mathematics with Lean 4"
    ]
  },
  {
    "objectID": "slide.html#what-is-lean-4",
    "href": "slide.html#what-is-lean-4",
    "title": "What is formalization",
    "section": "What is Lean 4",
    "text": "What is Lean 4\n\nA modern functional programming language designed for theorem proving\n\n\n“Lean is based on a version of dependent type theory known as the Calculus of Constructions, with a countable hierarchy of non-cumulative universes and inductive types.” — Theorem Proving in Lean 4",
    "crumbs": [
      "Introduction to Formal Mathematics with Lean 4"
    ]
  },
  {
    "objectID": "slide.html#leans-dependent-type-theory",
    "href": "slide.html#leans-dependent-type-theory",
    "title": "What is formalization",
    "section": "Lean’s dependent type theory",
    "text": "Lean’s dependent type theory\n\nDependent type theory is a powerful extension of type theory where\n\ntypes may depend on terms “given before” them\nfirst-order logic can be implemented in dependent type theory\n\nfunctions, inductive types and quotient types3 are the basic methods to construct new types.\n\n3 Though seemingly redundant, there are reasons for making quotient types as a fundamental constructing method. funext thesis\n\n\nSet Theory\nLean’s dependent type theory\n\n\n\n\n\\(\\forall x \\in \\mathbb R,\\, x^2 \\geq 0\\)\nhas type \\((x : \\mathbb R) \\to (x^2 \\geq 0)\\)\n\n\n\\((n \\in \\mathbb N) \\mapsto (1,0,\\dots,0) \\in \\mathbb R^n\\)\nhas type \\((n : \\mathbb N) \\to \\mathbb R^n\\)\n\n\n\\(\\{ 0,1 \\} = 2\\) is a set equality\nmake no sense\n\n\ncardinality is an equivalence class\nis a quotient type\n\n\nRussell’s paradox\nGirard’s paradox",
    "crumbs": [
      "Introduction to Formal Mathematics with Lean 4"
    ]
  },
  {
    "objectID": "slide.html#an-example-lean-4-code",
    "href": "slide.html#an-example-lean-4-code",
    "title": "What is formalization",
    "section": "An example Lean 4 code",
    "text": "An example Lean 4 code\n\nFLT\nTendsTo\n\nWhy formalize",
    "crumbs": [
      "Introduction to Formal Mathematics with Lean 4"
    ]
  },
  {
    "objectID": "slide.html#the-rise-of-ai",
    "href": "slide.html#the-rise-of-ai",
    "title": "What is formalization",
    "section": "The rise of AI",
    "text": "The rise of AI\nAI excels in Python. Why not Lean?\n\nAutomated theorem proving\n\nespecially those “abstract nonsense”\nfull-auto (create a proof without human interaction)\nsemi-auto (suggest tactics)\n\nexact?, Github Copilot, …\n\n\nNatural language to formal language\n\nautomatically transplanting textbooks and papers into Lean\nfull-auto (translate without human interaction)\nbolt-action (search for existing theorems)\n\nLeanSearch, LeanExplore, …\n\nConverse? Already happening!\n\nProposing conjectures\n\non which facts should we care about",
    "crumbs": [
      "Introduction to Formal Mathematics with Lean 4"
    ]
  },
  {
    "objectID": "slide.html#rigor-matters",
    "href": "slide.html#rigor-matters",
    "title": "What is formalization",
    "section": "Rigor matters",
    "text": "Rigor matters\n\nIt’s the foundation of mathematics\nImprecise natural language often leads to misunderstandings and glitches\n\nEspecially when proofs get longer and longer\n\nformalization fully confirms the correctness of a theorem\n\nthings that are too “technical” (boring) or simply impossible to verify by oneself\n\ne.g. classification of finite simple groups\ne.g. “technical”\n\n\n“I spent much of 2019 obsessed with the proof of this theorem, almost getting crazy over it. In the end, we were able to get an argument pinned down on paper, but I think nobody else has dared to look at the details of this, and so I still have some small lingering doubts.” — Peter Scholze",
    "crumbs": [
      "Introduction to Formal Mathematics with Lean 4"
    ]
  },
  {
    "objectID": "slide.html#mathematical-engineering",
    "href": "slide.html#mathematical-engineering",
    "title": "What is formalization",
    "section": "“Mathematical engineering”",
    "text": "“Mathematical engineering”\n\nmanipulating tons of theorems and proofs with mature software engineering techniques\nreferencing existing theorems as dependencies\ncollaborative work across the globe\n\n\nThe beauty of the system: you do not have to understand the whole proof of FLT in order to contribute. The blueprint breaks down the proof into many many small lemmas, and if you can formalise a proof of just one of those lemmas then I am eagerly awaiting your pull request. — Kevin Buzzard on the FLT Project",
    "crumbs": [
      "Introduction to Formal Mathematics with Lean 4"
    ]
  },
  {
    "objectID": "slide.html#formalization-as-learning",
    "href": "slide.html#formalization-as-learning",
    "title": "What is formalization",
    "section": "Formalization as learning",
    "text": "Formalization as learning\n\nproofs with infinite detail\n\nintuitive textbooks, rigorous formalization\n\nmakes us understand things better\n\nGlobal: How to build natural numbers from scratch?\n\nnatural number game\nA journey to the world of numbers, by Riccardo Brasca\n\nLocal: reducing the cognitive load\n\n(With good organization at the beginning) you can focus on small parts of the proof at a time\n\n\n\nWhy now formalize",
    "crumbs": [
      "Introduction to Formal Mathematics with Lean 4"
    ]
  },
  {
    "objectID": "slide.html#formalization-becomes-more-accessible",
    "href": "slide.html#formalization-becomes-more-accessible",
    "title": "What is formalization",
    "section": "Formalization becomes more accessible",
    "text": "Formalization becomes more accessible\nMathematician-friendly languages, interfaces, tools and community emerges:\n\nLean 4 with VSCode extension, modern interactive theorem prover made for mathematicians\nformalization becomes more and more fashionable\nbig names works on formalization:\n\nKevin Buzzard works on formalizing FLT\nPeter Scholze’s work on condensed mathematics has been formalized\nTerrence Tao gave a talk on formalization in IMO 2024 and wrote a Lean 4 companion of his book “Analysis I” recently\n\ncomputer scientists and volunteering mathematicians run Lean 4 community collaboratively",
    "crumbs": [
      "Introduction to Formal Mathematics with Lean 4"
    ]
  },
  {
    "objectID": "slide.html#mathlib-4-is-expanding-explosively",
    "href": "slide.html#mathlib-4-is-expanding-explosively",
    "title": "What is formalization",
    "section": "Mathlib 4 is expanding explosively",
    "text": "Mathlib 4 is expanding explosively\nBy the time of 2025/09/16, Mathlib 4 has4\n4 Statistics fetched from Mathlib statistics\n\n\nLines of code\nDefinitions\nTheorems\nContributors\n\n\n\n\n1950000\n115438\n232204\n653\n\n\n\n\nundergraduate may contribute: some low-hanging fruits\n\nHow to formalize",
    "crumbs": [
      "Introduction to Formal Mathematics with Lean 4"
    ]
  },
  {
    "objectID": "slide.html#the-goal",
    "href": "slide.html#the-goal",
    "title": "What is formalization",
    "section": "The goal",
    "text": "The goal\nThe goal, at the end of this course, is\n\nto get used to think formally\nto migrate from set theory to dependent type theory\nto practice basic skills to translate statements and proofs into Lean 4\nto know how to find existing theorems, how the community works\nto acquire enough common senses to read the bibles (MiL, TPiL, Mathlib 4 Doc, etc.) by yourself for future formalization projects\n(optimistically) to set up a Lean 4 formalization club at BIT!",
    "crumbs": [
      "Introduction to Formal Mathematics with Lean 4"
    ]
  },
  {
    "objectID": "slide.html#how-will-we-learn",
    "href": "slide.html#how-will-we-learn",
    "title": "What is formalization",
    "section": "How will we learn",
    "text": "How will we learn\nAs mathematicians, we learn Lean 4 to formalizing mathematics. We learn by practice.\n\nDozens of Lean files packed with well-organized examples and exercises suffice to get you started, suitable for both guided study and self study. Most lectures will be given in this style.\nThis style of teaching is inspired by Kevin Buzzard’s 2024 course on formalising mathematics in the Lean theorem prover and many other courses.",
    "crumbs": [
      "Introduction to Formal Mathematics with Lean 4"
    ]
  },
  {
    "objectID": "slide.html#what-we-wont-cover",
    "href": "slide.html#what-we-wont-cover",
    "title": "What is formalization",
    "section": "What we won’t cover",
    "text": "What we won’t cover\nDue to the limited time, my personal inability and the design of this course, we might not be able to cover:\n\na deep discussion into dependent type theory or Lean as a programming language itself\n\nRead TPiL for a Lean 4 tutorial that emphasizes on type theory.\nRead FPiL for a Lean 4 tutorial that focuses more on functional programming.\nRefer to Lean Language Manual for precise specifications.\n\nsystematic exposition of how a particular branch of mathematics is formalized in Mathlib 4\n\nRead MiL for this purpose.\n\nhow to organize a massive formalization project from scratch, i.e. project management\n\nsomewhat subtle, might can only be learned by reading Mathlib codes and practical experience",
    "crumbs": [
      "Introduction to Formal Mathematics with Lean 4"
    ]
  },
  {
    "objectID": "slide.html#disclaimer",
    "href": "slide.html#disclaimer",
    "title": "What is formalization",
    "section": "Disclaimer",
    "text": "Disclaimer\n\nFormalization is tedious in its nature, Lean is no exception\nType conversions can be an extra burden (exclusive for type-theory-based systems)\nKnowledge needs to be re-learned before being referenced\nDifferent people may formalize the same thing in different ways",
    "crumbs": [
      "Introduction to Formal Mathematics with Lean 4"
    ]
  },
  {
    "objectID": "slide.html#if-these-do-not-scare-you-away",
    "href": "slide.html#if-these-do-not-scare-you-away",
    "title": "What is formalization",
    "section": "If these do not scare you away…",
    "text": "If these do not scare you away…\nWelcome aboard. Have fun formalizing mathematics!",
    "crumbs": [
      "Introduction to Formal Mathematics with Lean 4"
    ]
  },
  {
    "objectID": "slide.html#resources",
    "href": "slide.html#resources",
    "title": "What is formalization",
    "section": "Resources",
    "text": "Resources\n\ncourse repository\nonline documentation",
    "crumbs": [
      "Introduction to Formal Mathematics with Lean 4"
    ]
  },
  {
    "objectID": "03-logic.html",
    "href": "03-logic.html",
    "title": "Logic (Part II)",
    "section": "",
    "text": "And and Or\nForall and Exists",
    "crumbs": [
      "Logic (Part II)"
    ]
  },
  {
    "objectID": "03-logic.html#and",
    "href": "03-logic.html#and",
    "title": "Logic (Part II)",
    "section": "1.1 And (∧)",
    "text": "1.1 And (∧)\n\nIntroducing And\nThe only constructor of And is And.intro, which takes a proof of p and a proof of q to produce a proof of p ∧ q.\nIt is self-evident. Regard this as the universal property of the direct product if you like.\n#check And.intro\n\nexample (hp : p) (hq : q) : p ∧ q := And.intro hp hq\nAnd.intro hp hq can be abbreviated as ⟨hp, hq⟩, called the anonymous constructor.\nexample (hp : p) (hq : q) : p ∧ q := ⟨hp, hq⟩\nintroducing nested And\nexample (hp : p) (hq : q) (hr : r) : p ∧ q ∧ r := by\n  exact ⟨hp, hq, hr⟩ -- equivalent to `⟨hp, ⟨hq, hr⟩⟩`\nconstructor tactic applies And.intro to split the goal p ∧ q into subgoals p and q. You may also use the anonymous constructor notation ⟨hp, hq⟩ to mean And.intro hp hq.\nuse · to focus on the first goal in your goal list.\nexample (hp : p) (hq : q) : p ∧ q := by\n  constructor\n  · exact hp\n  · exact hq\non_goal tactic can be used to focus on a specific goal.\nexample (hp : p) (hq : q) : p ∧ q := by\n  constructor\n  on_goal 2 =&gt; exact hq\n  exact hp\nall_goals tactic can be used to simultaneously perform tactics on all goals.\nexample (hp : p) : p ∧ p := by\n  constructor\n  all_goals exact hp\nassumption tactic tries to close goals using existing hypotheses in the context. Can be useful when there are many goals.\nexample (hp : p) (hq : q) : p ∧ q := by\n  constructor\n  all_goals assumption\nsplit_ands tactic is like constructor but works for nested Ands.\nexample (hp : p) (hq : q) (hr : r) : p ∧ q ∧ r := by\n  split_ands\n  · exact hp\n  · exact hq\n  · exact hr\n[EXR] →–∨ distribution. Universal property of the direct product.\nexample (hrp : r → p) (hrq : r → q) : r → p ∧ q := by\n  intro hr\n  exact ⟨hrp hr, hrq hr⟩\n\n\nEliminating And\nAnd.left and And.right are among the elimination rules of And, which extract the proofs of p and q.\n#check And.left\n#check And.right\nexample (hpq : p ∧ q) : p := hpq.left\nexample (hpqr : p ∧ q ∧ r) : r := hpqr.right.right\nrcases hpq with ⟨hp, hq⟩ is a tactic that breaks down the hypothesis hpq : p ∧ q into hp : p and hq : q. Equivalently you can use have ⟨hp, hq⟩ := hpq.\nexample (hpq : p ∧ q) : p := by\n  rcases hpq with ⟨hp, _⟩\n  exact hp\nimplicit break-down in intro\nexample : p ∧ q → p := by\n  intro ⟨hp, _⟩\n  exact hp\nnested And elimination\nexample (hpqr : p ∧ q ∧ r) : r := by\n  rcases hpqr with ⟨_, _, hr⟩\n  exact hr\n[EXR] And is symmetric\nexample : p ∧ q → q ∧ p := by\n  intro ⟨hp, hq⟩\n  exact ⟨hq, hp⟩\n#check And.comm -- above has a name\n[EXR] →–∨ distribution, in another direction.\nexample (hrpq : r → p ∧ q) : (r → p) ∧ (r → q) := by\n  constructor\n  · intro hr\n    exact (hrpq hr).left\n  · intro hr\n    exact (hrpq hr).right\n\n\nCurrification\nThe actual universal elimination rule of And is the so-called decurrification: From (p → q → r) we may deduce (p ∧ q → r). This is actually a logical equivalence.\nIntuitively, requiring both p and q to deduce r is nothing but requiring p to deduce that q is sufficient to deduce r.\n[IGNORE] Decurrification is also self-evidently true in Lean’s dependent type theory.\nCurrification is heavily used in functional programming for its convenience, Lean is no exception.\nYou are no stranger to decurrification even if you are not a functional programmer: The universal property of the tensor product of modules says exactly the same. \\[\n\\operatorname{Hom}(M \\otimes N, P) \\cong \\operatorname{Hom}(M, \\operatorname{Hom}(N, P))\n\\]\n[EXR] currification\nexample (h : p ∧ q → r) : (p → q → r) := by\n  intro hp hq\n  exact h ⟨hp, hq⟩\n[EXR] decurrification\nexample (h : p → q → r) : (p ∧ q → r) := by\n  intro hpq\n  exact h hpq.left hpq.right\n\nexample (h : p → q → r) : (p ∧ q → r) := by\n  intro ⟨hp, hq⟩ -- `intro` is smart enough to destructure `And`\n  exact h hp hq\n\nexample (h : p → q → r) : (p ∧ q → r) := by\n  intro ⟨hp, hq⟩\n  apply h -- `apply` is smart enough to auto-decurrify and generate two subgoals\n  · exact hp\n  · exact hq\n[IGNORE] decurrification actually originates from And.rec, which is self-evident\n#check And.rec\ntheorem decurrify (h : p → q → r) : (p ∧ q → r) := And.rec h\nAnd.left is actually a consequence of decurrification\nexample : p ∧ q → p := by\n  apply decurrify\n  intro hp _\n  exact hp",
    "crumbs": [
      "Logic (Part II)"
    ]
  },
  {
    "objectID": "03-logic.html#iff-first-visit",
    "href": "03-logic.html#iff-first-visit",
    "title": "Logic (Part II)",
    "section": "1.2 Iff (↔︎), first visit",
    "text": "1.2 Iff (↔︎), first visit\nIt’s high time to introduce Iff here for the first time.\nIff (↔︎) contains two side of implications: Iff.mp and Iff.mpr.\nThough it is defined as a distinct inductive type, Iff may be seen as a bundled version of (p → q) ∧ (q → p). you may, somehow, even use it like a (p → q) ∧ (q → p). The only major difference is the name of the two components.\n#check Iff.intro\n#check Iff.mp\n#check Iff.mpr\n\nexample : (p ↔ q) ↔ (p → q) ∧ (q → p) := by\n  constructor\n  · intro h\n    exact ⟨h.mp, h.mpr⟩\n  · intro ⟨hpq, hqp⟩\n    exact ⟨hpq, hqp⟩",
    "crumbs": [
      "Logic (Part II)"
    ]
  },
  {
    "objectID": "03-logic.html#or",
    "href": "03-logic.html#or",
    "title": "Logic (Part II)",
    "section": "1.3 Or (∨)",
    "text": "1.3 Or (∨)\n\nIntroducing Or\nOr has two constructors, Or.inl and Or.inr. Either a proof of p or a proof of q produces a proof of p ∨ q.\n#check Or.inl\n#check Or.inr\n\nexample (hp : p) : p ∨ q := Or.inl hp\nleft (resp. right) tactic reduce Or goals to p (resp. q)\nexample (hq : q) : p ∨ q := by\n  right\n  exact hq\n\n\nEliminating Or\nTo prove r from p ∨ q, it suffices to prove both p → r and q → r. This is the elimination rule of Or, or the universal property of the direct sum.\n#check Or.elim\n#check Or.rec -- [IGNORE]\n\nexample (hpr : p → r) (hqr : q → r) : (p ∨ q → r) := fun hpq ↦ (Or.elim hpq hpr hqr)\nexample (hpr : p → r) (hqr : q → r) : (p ∨ q → r) := (Or.elim · hpr hqr) -- note the use of `·`\nexample (hpr : p → r) (hqr : q → r) (hpq : p ∨ q) : r := by\n  apply Or.elim hpq\n  · exact hpr\n  · exact hqr\nmatch-style syntax is designed to make use of Or.elim to destructure Or to cases. [IGNORE] You may just skim through this syntax for now.\nexample (hpr : p → r) (hqr : q → r) : (p ∨ q → r) := fun\n  | Or.inl hp =&gt; hpr hp\n  | Or.inr hq =&gt; hqr hq\nexample (hpr : p → r) (hqr : q → r) (hpq : p ∨ q) : r :=\n  match hpq with\n  | Or.inl hp =&gt; hpr hp\n  | Or.inr hq =&gt; hqr hq\nexample (hpr : p → r) (hqr : q → r) (hpq : p ∨ q) : r := by\n  match hpq with\n  | Or.inl hp =&gt; exact hpr hp\n  | Or.inr hq =&gt; exact hqr hq\nexample (hpr : p → r) (hqr : q → r) (hpq : p ∨ q) : r := by\n  cases hpq with\n  | inl hp =&gt; exact hpr hp\n  | inr hq =&gt; exact hqr hq\nrcases may also serve as a tactic version of match, which is much more convenient.\nexample (hpr : p → r) (hqr : q → r) (hpq : p ∨ q) : r := by\n  rcases hpq with (hp | hq) -- `rcases` can also destructure `Or`\n  · exact hpr hp\n  · exact hqr hq\nexample (hpr : p → r) (hqr : q → r) : p ∨ q → r := by\n  rintro (hp | hq) -- `rintro` is a combination of `intro` and `rcases`\n  · exact hpr hp\n  · exact hqr hq\n[EXR] distributive laws\nexample : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) := by sorry\nexample : p ∨ (q ∧ r) ↔ (p ∨ q) ∧ (p ∨ r) := by sorry\n\nend",
    "crumbs": [
      "Logic (Part II)"
    ]
  },
  {
    "objectID": "03-logic.html#forall",
    "href": "03-logic.html#forall",
    "title": "Logic (Part II)",
    "section": "2.1 Forall (∀)",
    "text": "2.1 Forall (∀)\nAs you may have already noticed, ∀ is just an alternative way of writing →. Say p is a predicate on a type X, i.e. of type X → Prop, then ∀ x : X, p x is exactly the same as (x : X) → p x.\nThough → is primitive in Lean’s dependent type theory, we may still (perhaps awkwardly) state the introduction and elimination rules of ∀:\n\nIntroduction: fun (x : X) ↦ (h x : p x) produces a proof of ∀ x : X, p x.\nElimination: Given a proof h of ∀ x : X, p x, we can obtain a proof of p a for any specific a : X. It is exactly h a.\n\nsection\n\nvariable {X : Type} (p q : X → Prop) (r s : Prop) (a b : X)\n\n#check ∀ x : X, p x\n#check ∀ x, p x -- Lean is smart enough to infer the type of `x`\n\nexample : (∀ x : X, p x) → p a := by\n  intro h\n  exact h a\n[IGNORE] Writing ∀ emphasizes that the arrow → is of dependent type, and the domain X is a type, not a proposition. But they are just purely psychological, as the following examples show.\nexample : (hrs : r → s) → (∀ _ : r, s) := by\n  intro hrs\n  exact hrs",
    "crumbs": [
      "Logic (Part II)"
    ]
  },
  {
    "objectID": "03-logic.html#exists",
    "href": "03-logic.html#exists",
    "title": "Logic (Part II)",
    "section": "2.2 Exists (∃)",
    "text": "2.2 Exists (∃)\n∃ is a bit more complicated.\nSlogan: ∀ is a dependent →, ∃ is a dependent × (or ∧ in Prop universe)\n#check ∃ x : X, p x\n#check ∃ x, p x -- Lean is smart enough to infer the type of `x`\n\nIntroducting Exists\n∃ x : X, p x means that we have the following data:\n\nan element a : X;\na proof h : p a.\n\nSo a pair (a, h) would suffice to construct a proof of ∃ x : X, p x.\nThis is the defining introduction rule of Exists as an inductive type.\n#check Exists.intro\nexample (a : X) (h : p a) : ∃ x, p x := Exists.intro a h\nAs like And, you may use the anonymous constructor notation ⟨a, h⟩ to mean Exists.intro a h.\nexample (a : X) (h : p a) : ∃ x, p x := ⟨a, h⟩\nIn tactic mode, use a make use of Exists.intro a to reduce the goal ∃ x : X, p x to p a.\nexample (a : X) (h : p a) : ∃ x, p x := by use a\n\n-- [EXR]\nexample (x y z : ℕ) (hxy : x &lt; y) (hyz : y &lt; z) : ∃ w, x &lt; w ∧ w &lt; z :=\n  ⟨y, ⟨hxy, hyz⟩⟩\nNote that in the defining pair (a, h), h is a proof of p a, whose type depends on a. Thus psychologically, you may view ∃ x : X, p x as a dependent pair type (x : X) × (p x).\nHave writing Exists as a dependent pair type reminded you of the currification process?\n\n\nEliminating Exists\nTo construct the implication (∃ x : X, p x) → q, it suffices to have a proof of (∀ x : X, p x → q), i.e. (x : X) → p x → q. Exists.elim does exactly above.\n#check Exists.elim\n\nexample : (∀ x, p x → r) → ((∃ x, p x) → r) := by\n  intro hf he\n  exact Exists.elim he hf\nIn tactic mode, rcases h with ⟨a, ha⟩ make use of this elimination rule to break down a hypothesis h : ∃ x : X, p x into a witness a : X and a proof ha : p a.\nexample : (∀ x, p x → r) → ((∃ x, p x) → r) := by\n  intro hf he\n  rcases he with ⟨a, hpa⟩\n  exact hf a hpa\n\nexample : (∀ x, p x → r) → ((∃ x, p x) → r) := by\n  intro h ⟨a, hpa⟩ -- you may also `rcases` explicitly\n  exact h a hpa\n[EXR] reverse direction is also true\nexample :  ((∃ x, p x) → r) → (∀ x, p x → r) := by\n  intro h a hpa\n  apply h\n  use a\n\n-- [EXR]\nexample : (∃ x, r ∧ p x) → r ∧ (∃ x, r ∧ p x) := by\n  intro ⟨a, ⟨hr, hpa⟩⟩\n  exact ⟨hr, ⟨a, ⟨hr, hpa⟩⟩⟩\n\n-- [EXR]\nexample : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) := by\n  constructor\n  · rintro ⟨a, (hpa | hqa)⟩\n    · left; use a\n    · right; use a\n  · rintro (⟨a, hpa⟩ | ⟨a, hqa⟩)\n    · use a; left; exact hpa\n    · use a; right; exact hqa\n\nend\n\n\n[IGNORE] A cosmological remark\nThe pair (a, h) actually do not have type (x : X) × (p x). The latter notation is actually for the dependent pair type (or Sigma type), which lives in Type* universe.\nBut Exists should live in Prop, and in Prop universe we admit proof-irrelevance, i.e. we do not save data. So Exists forget the exact witness a once it is proved.\nThis “forgetfulness” is revealed by the fact that there is no elimination rule Exists.fst to extract the witness a from a proof of ∃ x : X, p x, as long as X lives in the Type* universe. (Note that Exists.elim can only produce propositions in Prop)\nBut if X lives in Prop universe, then we do have Exists.fst:\nsection\n\n#check Exists.fst\nWait, wait, we never worked with X : Prop before. Say p : r → Prop and r s : Prop, what does ∃ hr : r, p hr mean? It means that r and p hr are both true? [TODO] I don’t know how to explain this properly so far.\nvariable (r : Prop) (p : r → Prop)\n#check ∃ hr : r, p hr\n\n-- Prove `Exists.fst` and `Exists.snd` by `Exists.elim`\nexample (he : ∃ hr : r, p hr) : r ∧ p he.fst := by\n  apply Exists.elim he\n  intro hr hpr\n  exact ⟨hr, hpr⟩\n\nend",
    "crumbs": [
      "Logic (Part II)"
    ]
  },
  {
    "objectID": "09-subgroup.html",
    "href": "09-subgroup.html",
    "title": "Substructures and Subgroups",
    "section": "",
    "text": "Diffrent people formalize things differently. This is especially true when it comes to substructures and quotients.\nIn this file, we show how to use the Mathlib’s API for substructures, from subsets to subgroups. It’s a sophisticated hierarchy that I’m still trying to fully understand myself. For the philosophy behind this design, see MiL chapter 8.",
    "crumbs": [
      "Substructures and Subgroups"
    ]
  },
  {
    "objectID": "09-subgroup.html#objects",
    "href": "09-subgroup.html#objects",
    "title": "Substructures and Subgroups",
    "section": "4.1 Objects",
    "text": "4.1 Objects\nThere’s nothing new about Subgroup G of a Group G compared to Subsemigroup and Submonoid. It just adds the closure under taking inverses.\nsection\n\nvariable (G : Type*) [Group G]\nvariable (H₁ H₂ : Subgroup G) (a b : G)\nexample : a ∈ H₁ → b ∈ H₁ → a * b ∈ H₁ := by apply mul_mem\nexample : (1 : G) ∈ H₁ := by apply one_mem\nexample : a ∈ H₁ → a⁻¹ ∈ H₁ := by apply inv_mem\nWe skip the lattice structure again.\nend",
    "crumbs": [
      "Substructures and Subgroups"
    ]
  },
  {
    "objectID": "09-subgroup.html#morphisms",
    "href": "09-subgroup.html#morphisms",
    "title": "Substructures and Subgroups",
    "section": "4.2 Morphisms",
    "text": "4.2 Morphisms\nMonoidHom works for Subgroup as well.\nsection\n\nvariable {G₁ G₂ : Type*} [Group G₁] [Group G₂]\n         (f : G₁ →* G₂) (H₁ : Subgroup G₁) (H₂ : Subgroup G₂)\nImage and preimage of subgroups, upgraded to show closure under inverses.\n#check Subgroup.map\n#check Subgroup.comap\nFor groups, mker and mrange has been upgraded to ker and range respectively.\n#check MonoidHom.ker\n#check MonoidHom.range\n\nexample : MonoidHom.ker f = (⊥ : Subgroup G₂).comap f := by rfl\nexample : MonoidHom.ker f = {MonoidHom.mker f with\n      inv_mem' := by simp\n    } := by rfl\n\nend",
    "crumbs": [
      "Substructures and Subgroups"
    ]
  },
  {
    "objectID": "09-subgroup.html#exercise",
    "href": "09-subgroup.html#exercise",
    "title": "Substructures and Subgroups",
    "section": "3.2 Exercise",
    "text": "3.2 Exercise\nAs an exercise, let’s define addition on AddSubmonoid A with the intrinsic definition, and show that it coincides with the supremum.\nsection\n\nvariable {A : Type*} [AddCommMonoid A]\n\ninstance : Add (AddSubmonoid A) := ⟨fun B₁ B₂ ↦ {\n  carrier := {x | ∃ b₁ ∈ B₁, ∃ b₂ ∈ B₂, x = b₁ + b₂}\n  zero_mem' := ⟨0, B₁.zero_mem, 0, B₂.zero_mem, by rw [add_zero]⟩\n  add_mem' := by\n    rintro x y ⟨b₁, hb₁, b₂, hb₂, rfl⟩ ⟨c₁, hc₁, c₂, hc₂, rfl⟩\n    use b₁ + c₁, B₁.add_mem hb₁ hc₁\n    use b₂ + c₂, B₂.add_mem hb₂ hc₂\n    abel\n}⟩\n\nexample (B₁ B₂ : AddSubmonoid A) : B₁ ⊔ B₂ = B₁ + B₂ := by\n  apply le_antisymm\n  · apply sup_le\n    · intro x hx\n      use x, hx, 0, B₂.zero_mem\n      rw [add_zero]\n    · intro x hx\n      use 0, B₁.zero_mem, x, hx\n      rw [zero_add]\n  · intro x hx\n    rcases hx with ⟨b₁, hb₁, b₂, hb₂, rfl⟩\n    haveI : B₁ ≤ B₁ ⊔ B₂ := le_sup_left\n    replace hb₁ : b₁ ∈ B₁ ⊔ B₂ := this hb₁\n    haveI : B₂ ≤ B₁ ⊔ B₂ := le_sup_right\n    replace hb₂ : b₂ ∈ B₁ ⊔ B₂ := this hb₂\n    exact add_mem hb₁ hb₂\n\nend",
    "crumbs": [
      "Substructures and Subgroups"
    ]
  },
  {
    "objectID": "09-subgroup.html#normal-subgroups",
    "href": "09-subgroup.html#normal-subgroups",
    "title": "Substructures and Subgroups",
    "section": "4.3 Normal Subgroups",
    "text": "4.3 Normal Subgroups\nFor later discussions on quotient groups, we introduce normal subgroups here.\nsection\n\n#check Subgroup.Normal\nSubgroup.Normal is a bundled structure consisting of a proof of normality.\nexample {G : Type*} [Group G] (H : Subgroup G) :\n    H.Normal ↔ ∀ h ∈ H, ∀ g : G, g * h * g⁻¹ ∈ H := by\n  constructor\n  · intro ⟨h⟩\n    exact h\n  · intro h\n    exact ⟨h⟩\nThe kernel of a group homomorphism is a normal subgroup.\nexample {G₁ G₂ : Type*} [Group G₁] [Group G₂]\n    (f : G₁ →* G₂) : (f.ker).Normal := by\n  constructor\n  intro x hx y\n  rw [MonoidHom.mem_ker]\n  rw [map_mul, map_mul, hx, map_inv, mul_one, mul_inv_cancel]\nActually, Mathlib contains an instance for kernels, so that Lean automatically recognizes the normality of kernels.\n#check MonoidHom.normal_ker\nexample {G₁ G₂ : Type*} [Group G₁] [Group G₂]\n    (f : G₁ →* G₂) : (f.ker).Normal := inferInstance\n\nend\n[TODO]\n\nIndexed infimum and supremum of substructures\nxxxClass for substructures as canonical maps",
    "crumbs": [
      "Substructures and Subgroups"
    ]
  },
  {
    "objectID": "10-quotient.html",
    "href": "10-quotient.html",
    "title": "Quotients and Quotient Groups",
    "section": "",
    "text": "After building up the theory of groups, homorphisms, and subgroups, we are now ready to define quotient groups.\nIn fact, quotients are so fundamental that Lean makes them a primitive way of constructing new types.\nWe shall first illustrate the general quotient construction in Lean, and then specialize it to quotient groups.\nAt the end of the journey, we show the first isomorphism theorem for groups as promised.\nimport Mathlib\n\n1 Quotient Sets\nWe still build up the theory from sets. First, we need to define equivalence relations on a type α. As you can guess, a binary relation r is just a α → α → Prop.\nsection\n\nvariable {α : Type*} {r : α → α → Prop} (a b c : α)\nEquivalence r is a bundled structure that packages the three properties:\n\nreflexivity of r\nsymmetry of r\ntransitivity of r\n\nvariable (r_equiv : Equivalence r)\n\nexample : r a a := by exact r_equiv.refl _\nexample : r a b → r b a := by exact r_equiv.symm\nexample : r a b → r b c → r a c := by exact r_equiv.trans\nIn mathmatics we often denote equivalence relations by ~. In Lean, we can also use ≈ as notation for equivalence relations, once we register the Setoid instance for α.\nThe Setoid typeclass is a bundle of\n\nan equivalence relation r on α\nthe proof that r is an equivalence relation.\n\ninstance r_setoid : Setoid α where\n  r := r\n  iseqv := r_equiv\n\nend",
    "crumbs": [
      "Quotients and Quotient Groups"
    ]
  },
  {
    "objectID": "01-intro.html",
    "href": "01-intro.html",
    "title": "At the Very Beginning",
    "section": "",
    "text": "You may skip the materials tagged with [IGNORE] for the first runthrough. Most of them are here to illustrate the nature of inductive types, which may be too advanced for beginners.\nMaterials tagged with [EXR] are recommended for you to try before looking at the solution.\nMaterials tagged with [TODO] means that I’m still working on it, or I’m not sure about the content yet. Feel free to give your suggestions!\n\n1 A First Glance\nHave a look at the sample Lean code below. Can you understand what it means, without any prior knowledge of Lean?\nimport Mathlib\n\ntheorem FLT (n : ℕ) (hn : n &gt; 2) (a b c : ℕ) :\n    a ≠ 0 → b ≠ 0 → c ≠ 0 → a^n + b^n ≠ c^n := by\n  sorry\n\ndef TendsTo (a : ℕ → ℝ) (t : ℝ) : Prop :=\n  ∀ ε &gt; 0, ∃ n₀ : ℕ, ∀ n, n₀ ≤ n → |a n - t| &lt; ε\n\nexample : TendsTo (fun _ ↦ 998244353) 998244353 := by\n  unfold TendsTo\n  intro ε hε\n  use 19260817\n  intro n hn\n  simp [hε]\n\ntheorem tendsTo_add {a b : ℕ → ℝ} {A : ℝ} {B : ℝ} (ha : TendsTo a A) (hb : TendsTo b B) :\n    TendsTo (fun n =&gt; a n + b n) (A + B) := by\n  sorry\n\ntheorem tendsTo_sandwich {a b c : ℕ → ℝ} {L : ℝ} (ha : TendsTo a L) (hc : TendsTo c L)\n    (hab : ∀ n, a n ≤ b n) (hbc : ∀ n, b n ≤ c n) : TendsTo b L := by\n  sorry\n\n\n2 At the Very Beginning…\nThere are some basic notions you should be familiar with: : and :=.\n3 : ℕ means that 3 is a term of type ℕ.\nBy the Curry–Howard correspondence, hp : p means that hp is a proof of the proposition p.\n#check 3\n#check ℕ\n\n#check ∀ x : ℝ, 0 ≤ x ^ 2\n#check sq_nonneg\n#check (sq_nonneg : ∀ x : ℝ, 0 ≤ x ^ 2)\n:= is used to define terms.\ndef myThree : ℕ := 3\n\n#check myThree\ntheorem is just a definition in the Prop universe By the Curry–Howard correspondence, for theorem, behind :, the theorem statement follows; behind :=, a proof should be given.\ntheorem thm_sq_nonneg : ∀ x : ℝ, 0 ≤ x ^ 2 := sq_nonneg\n\n-- `example` is just an anonymous theorem\nexample : ∀ x : ℝ, 0 ≤ x ^ 2 := thm_sq_nonneg\nWe shall work out the basic logic in Lean’s dependent type theory.\nIn this part, we cover:\n\nImplication\n\nSyntax for defining functions / theorems\n\nTactic Mode\n\n[IGNORE] You may notice along the way that except →, all other logical connectives are defined as inductive types. And they have their own self-evident introduction rules and elimination rules. We shall discuss inductive types later in this course. These logical connectives serve as good examples.",
    "crumbs": [
      "At the Very Beginning"
    ]
  },
  {
    "objectID": "08-group.html",
    "href": "08-group.html",
    "title": "Groups and Homomorphisms",
    "section": "",
    "text": "In this file, we illustrate how Mathlib develops the theory of everyday algebraic structures, starting from semigroups, monoids, groups, and their morphisms.\nBy “illustrate”, we do not mean to reconstruct these structures from scratch, as we haven’t yet covered how to define structures and type classes in Lean.\nInstead, we accept the Mathlib definitions and axioms, but reprove some of their consequences manually, with mention of the relevant theorems in Mathlib.\nHopefully, this will help you focus on building up the theory mathematically while getting familiar with the Mathlib API. Be advised that you can always ctrl+click on any name to see its actual definition in Mathlib.\nFor a more complete treatment (especially on the philosophy behind API design), read MiL chapter 7 and 9.",
    "crumbs": [
      "Groups and Homomorphisms"
    ]
  },
  {
    "objectID": "08-group.html#objects",
    "href": "08-group.html#objects",
    "title": "Groups and Homomorphisms",
    "section": "3.1 Objects",
    "text": "3.1 Objects\nIn Mathlib, a Group is defined to be a Monoid where every element a has an left inverse a⁻¹ s.t. a⁻¹ * a = 1.\nsection\n\n#check Group\nvariable (G : Type*) [Group G] (a b c : G)\n#check a⁻¹\nexample : a⁻¹ * a = 1 := by rw [inv_mul_cancel]\nThe following exercises lead to a proof of: In a group, a left inverse is also a right inverse. This recovers the usual definition of a group.\n[EXR] left multiplication is injective\nexample (h : a * b = a * c) : b = c := by\n  apply_fun (a⁻¹ * ·) at h\n  rw [← mul_assoc, ← mul_assoc, inv_mul_cancel, one_mul, one_mul] at h\n  exact h\n#check mul_left_cancel -- this has a name\n[EXR] a left inverse actually also a right inverse\nexample : a * a⁻¹ = 1 := by\n  apply_fun (a⁻¹ * ·)\n  · dsimp\n    rw [← mul_assoc, inv_mul_cancel, one_mul, mul_one]\n  · apply mul_left_cancel\n#check mul_inv_cancel -- this has a name\nThe following proves that G is a DivisionMonoid. You don’t need to know what this means for now.\n#synth DivisionMonoid G\n[EXR] characterization of a right inverse\nexample (h : a * b = 1) : b = a⁻¹ := by\n  -- if you does not want to use `apply_fun`\n  rw [← one_mul b, ← inv_mul_cancel a, mul_assoc, h, mul_one]\n#check eq_inv_of_mul_eq_one_right -- this has a name\n[EXR] characterization of a left inverse\nexample (h : a * b = 1) : a = b⁻¹ := by\n  apply_fun (· * b⁻¹) at h\n  rw [mul_assoc, mul_inv_cancel, mul_one, one_mul] at h\n  exact h\n#check eq_inv_of_mul_eq_one_left -- this has a name\n[EXR] involutivity of the inverse\nexample : (a⁻¹)⁻¹ = a := by\n  symm; apply eq_inv_of_mul_eq_one_right\n  exact inv_mul_cancel a\n#check inv_inv -- this has a name\n[EXR] inverse of a product\nexample : (a * b)⁻¹ = b⁻¹ * a⁻¹ := by\n  apply inv_eq_of_mul_eq_one_left\n  rw [← mul_assoc, mul_assoc b⁻¹, inv_mul_cancel, mul_one, inv_mul_cancel]\n#check mul_inv_rev -- this has a name\nsome other injectivity\n[EXR] inverse is injective\nexample (h : a⁻¹ = b⁻¹) : a = b := by\n  apply_fun (·⁻¹) at h\n  rw [inv_inv a, inv_inv b] at h\n  exact h\n#check inv_injective -- this has a name\n[EXR] right multiplication is injective\nexample (h : b * a = c * a) : b = c := by\n  apply_fun (· * a⁻¹) at h\n  rw [mul_assoc, mul_assoc, mul_inv_cancel, mul_one, mul_one] at h\n  exact h\n#check mul_right_cancel -- this has a name\nwheelchair tactic for groups\n#help tactic group\nexample : (a ^ 3 * b⁻¹)⁻¹ = b * a⁻¹ * (a ^ 2)⁻¹  := by\n  group\n[TODO] DivInvMonoid enables zpow notation for integer powers a ^ n where n : ℤ.\n[IGNORE] It extends npow for monoids. See the library note [forgetful inheritance] for the philosophy of this definition.\nAdditive and commutative versions of groups are as usual.\n#check AddGroup\n#check CommGroup\n#check AddCommGroup\n\nend",
    "crumbs": [
      "Groups and Homomorphisms"
    ]
  },
  {
    "objectID": "08-group.html#morphisms",
    "href": "08-group.html#morphisms",
    "title": "Groups and Homomorphisms",
    "section": "3.2 Morphisms",
    "text": "3.2 Morphisms\nMonoidHom It is also used for group homomorphisms.\nsection\n\nvariable {G₁ G₂ G₃ : Type*} [Group G₁] [Group G₂] [Group G₃]\n         (f : G₁ →* G₂) (g : G₂ →* G₃) (a b : G₁)\n[EXR] Monoid homomorphisms preserve inverses\nexample : f (a⁻¹) = (f a)⁻¹ := by\n  apply eq_inv_of_mul_eq_one_right\n  rw [← map_mul, mul_inv_cancel, map_one]\n#check map_inv -- this has a name\n[EXR] MonoidHom requires one to show preservation of 1. But this is redundant for group homomorphisms.\nexample (φ : G₁ →ₙ* G₂) : φ 1 = 1 := by\n  haveI : φ 1 * φ 1 = φ 1 * 1 := by rw [← map_mul, mul_one, mul_one]\n  exact mul_left_cancel this\nHence in the case of groups, Mathlib provides a constructor MonoidHom.mk' that only requires the preservation of multiplication to build a MonoidHom.\n#check MonoidHom.mk'\n\nend",
    "crumbs": [
      "Groups and Homomorphisms"
    ]
  },
  {
    "objectID": "07-analysis.html",
    "href": "07-analysis.html",
    "title": "Mathematical Analysis",
    "section": "",
    "text": "Finally some real math in Lean! In this file we show how to define limits of sequences and continuity of functions in Lean. Of course it is just a toy version, far from the real Mathlib definitions. Nevertheless, that should be enough for you to get a taste of formalizing something that is not completely trivial.\nSince we haven’t touch division quite much yet, you may find it’s difficult to deal with multiplication and division. field_simp tactic may help you a lot in such cases. It won’t break things up as simp does. Anyway, don’t worry too much about it for now.\nimport Mathlib\n\ndef TendsTo (a : ℕ → ℝ) (t : ℝ) : Prop :=\n  ∀ ε &gt; 0, ∃ n₀ : ℕ, ∀ n, n₀ ≤ n → |a n - t| &lt; ε\n[EXR] The limit of the constant sequence with value c is c.\ntheorem tendsTo_const (c : ℝ) : TendsTo (fun _ ↦ c) c := by\n  unfold TendsTo\n  intro ε hε\n  use 1\n  intro n hn\n  simp [hε]\n- commutes with tendsTo\ntheorem tendsTo_neg {a : ℕ → ℝ} {t : ℝ} (ha : TendsTo a t) : TendsTo (fun n ↦ -a n) (-t) := by\n  unfold TendsTo\n  intro ε hε\n  specialize ha ε hε\n  rcases ha with ⟨n₀, hn₀⟩\n  use n₀\n  intro n hn\n  specialize hn₀ n hn\n  simp\n  -- what theorems should I use?\n  rw [← abs_neg, add_comm]\n  simp\n  -- what theorems should I use?\n  rw [← sub_eq_add_neg]\n  exact hn₀\n+ commutes with tendsTo\ntheorem tendsTo_add {a b : ℕ → ℝ} {A : ℝ} {B : ℝ} (ha : TendsTo a A) (hb : TendsTo b B) :\n    TendsTo (fun n =&gt; a n + b n) (A + B) := by\n  intro ε hε\n  specialize ha (ε / 2) (by linarith only [hε])\n  specialize hb (ε / 2) (by linarith only [hε])\n  rcases ha with ⟨n₀, ha⟩\n  rcases hb with ⟨m₀, hb⟩\n  use max n₀ m₀\n  intro n hn\n  -- what theorems should I use?\n  rw [max_le_iff] at hn\n  specialize ha n (by linarith only [hn.left])\n  specialize hb n (by linarith only [hn.right])\n  simp\n  -- common tactic: eliminate abs to make use of `linarith`\n  -- what theorems should I use?\n  rw [abs_lt] at ha hb ⊢\n  constructor\n  · linarith only [ha, hb]\n  · linarith only [ha, hb]\n[EXR] - commutes with tendsTo\ntheorem tendsTo_sub {a b : ℕ → ℝ} {A B : ℝ} (ha : TendsTo a A) (hb : TendsTo b B) :\n    TendsTo (fun n =&gt; a n - b n) (A - B) := by\n  haveI := tendsTo_add ha (tendsTo_neg hb)\n  -- [TODO] `congr` closes the goal directly here. Find out why.\n  ring_nf at this\n  exact this\n≤ version of TendsTo is equivalent to the usual TendsTo.\ndef TendsTo_le (a : ℕ → ℝ) (t : ℝ) : Prop :=\n  ∀ ε &gt; 0, ∃ n₀ : ℕ, ∀ n, n₀ ≤ n → |a n - t| ≤ ε\n\n-- [EXR]\ntheorem tendsTo_le_iff_TendsTo {a : ℕ → ℝ} {t : ℝ} : TendsTo_le a t ↔ TendsTo a t := by\n  constructor\n  · intro h ε hε\n    rcases h (ε / 2) (by linarith [hε]) with ⟨n₀, hn₀⟩\n    use n₀\n    intro n hn; specialize hn₀ n hn\n    linarith only [hn₀, hε]\n  · intro h ε hε\n    rcases h ε hε with ⟨n₀, hn₀⟩\n    use n₀\n    intro n hn; specialize hn₀ n hn\n    linarith only [hn₀, hε]\na weaker version of TendsTo where we require ε &lt; l. When l &gt; 0, this is equivalent to TendsTo.\ndef TendsTo_εlt (a : ℕ → ℝ) (t : ℝ) (l : ℝ) : Prop :=\n  ∀ ε &gt; 0, ε &lt; l → ∃ n₀ : ℕ, ∀ n, n₀ ≤ n → |a n - t| &lt; ε\n\ntheorem tendsTo_εlt_iff_TendsTo {a : ℕ → ℝ} {t : ℝ} {l : ℝ} (l_gt_zero : l &gt; 0) :\n    TendsTo_εlt a t l ↔ TendsTo a t := by\n  constructor\n  · intro h ε hε\n    specialize h (min ε (l / 2))\n                 (by apply lt_min; all_goals linarith)\n                 (by apply min_lt_of_right_lt; linarith only [l_gt_zero])\n    rcases h with ⟨n₀, hn₀⟩; use n₀\n    intro n hn; specialize hn₀ n hn\n    rw [lt_min_iff] at hn₀\n    exact hn₀.left\n  · exact fun h ε hε _ ↦ h ε hε\n* commutes with tendsTo. [TODO] I failed to finish the proof swiftly. You are welcome to optimize it!\ntheorem tendsTo_mul {a b : ℕ → ℝ} {A B : ℝ} (ha : TendsTo a A) (hb : TendsTo b B) :\n    TendsTo (fun n ↦ a n * b n) (A * B) := by\n  rw [← tendsTo_εlt_iff_TendsTo (show 1 &gt; 0 by linarith)]\n  intro ε hε hεlt1; simp\n  specialize ha (ε / (3 * (|B| + 1))) (by\n    apply div_pos hε\n    linarith only [abs_nonneg B])\n  rcases ha with ⟨n₁, ha⟩\n  specialize hb (ε / (3 * (|A| + 1))) (by\n    apply div_pos hε\n    linarith only [abs_nonneg A])\n  rcases hb with ⟨n₂, hb⟩\n  use max n₁ n₂\n  intro n hn\n  rw [max_le_iff] at hn\n  specialize ha n hn.left\n  specialize hb n hn.right\n  rw [show a n * b n - A * B = (a n - A) * (b n - B) + A * (b n - B) + B * (a n - A) by ring]\n  repeat grw [abs_add]\n  repeat grw [abs_mul]\n  grw [ha, hb]\n  -- sometimes you have no choice but add some manual steps\n  have h1 : |A| * (ε / (3 * (|A| + 1))) &lt; ε / 3 := by\n    field_simp\n    rw [div_lt_iff₀]\n    · ring_nf\n      linarith only [hε]\n    · linarith only [abs_nonneg A]\n  have h2 : |B| * (ε / (3 * (|B| + 1))) &lt; ε / 3 := by\n    field_simp\n    rw [div_lt_iff₀]\n    · ring_nf\n      linarith only [hε]\n    · linarith only [abs_nonneg B]\n  have h3 : ε / (3 * (|B| + 1)) * (ε / (3 * (|A| + 1))) &lt; ε / 3 := by\n    field_simp\n    rw [div_lt_iff₀]\n    · repeat grw [← abs_nonneg]\n      ring_nf\n      calc\n        _ = ε * ε := by ring\n        _ ≤ 1 * ε := by grw [← hεlt1]\n        _ = ε     := by ring\n        _ &lt; ε * 3 := by linarith only [hε]\n    · repeat grw [← abs_nonneg]\n      ring_nf\n      linarith only\n  linarith only [h1, h2, h3]\nsqueeze theorem for sequences\ntheorem tendsTo_sandwich {a b c : ℕ → ℝ} {L : ℝ} (ha : TendsTo a L) (hc : TendsTo c L)\n    (hab : ∀ n, a n ≤ b n) (hbc : ∀ n, b n ≤ c n) : TendsTo b L := by\n  unfold TendsTo\n  intro ε hε\n  specialize ha ε hε\n  specialize hc ε hε\n  rcases ha with ⟨n₀, hn₀⟩\n  rcases hc with ⟨m₀, hm₀⟩\n  use max n₀ m₀\n  intro n hn\n  rw [max_le_iff] at hn\n  specialize hab n\n  specialize hn₀ n (by linarith only [hn.left])\n  specialize hm₀ n (by linarith only [hn.right])\n  specialize hbc n\n  rw [abs_lt] at hn₀ hm₀ ⊢\n  constructor\n  · linarith only [hn₀, hm₀, hbc, hab]\n  · linarith only [hn₀, hm₀, hbc, hab]\nconstant sequence tends to zero iff condition\ntheorem tendsTo_zero_iff_lt_ε {x : ℝ} : TendsTo (fun _ ↦ x) 0 ↔ (∀ ε &gt; 0, |x| &lt; ε) := by\n  constructor\n  · intro h ε hε\n    specialize h ε hε\n    rcases h with ⟨n₀, hn₀⟩\n    specialize hn₀ n₀ (by linarith only)\n    simp at hn₀; exact hn₀\n  · intro h\n    intro ε hε\n    specialize h ε hε\n    use 0\n    intro n hn\n    simp; exact h\n[EXR] zero sequence tends to x iff condition\ntheorem zero_tendsTo_iff_lt_ε {x : ℝ} : TendsTo (fun _ ↦ 0) x ↔ (∀ ε &gt; 0, |x| &lt; ε) := by\n  constructor\n  · intro h\n    unfold TendsTo at h; simp at h\n    intro ε hε\n    specialize h ε hε\n    rcases h with ⟨n₀, hn₀⟩\n    specialize hn₀ n₀ (by linarith only)\n    exact hn₀\n  · intro h\n    intro ε hε\n    use 0\n    intro n hn\n    simp\n    exact h ε hε\nuniqueness of limits\ntheorem tendsTo_unique (a : ℕ → ℝ) (s t : ℝ) (hs : TendsTo a s) (ht : TendsTo a t) : s = t := by\n  by_contra! hneq\n  have hstp : 0 &lt; |t - s| := by\n    rw [abs_pos]\n    contrapose! hneq\n    apply_fun fun x ↦ x + s at hneq\n    simp at hneq\n    symm\n    exact hneq\n  have hst := tendsTo_sub hs ht\n  simp at hst\n  rw [zero_tendsTo_iff_lt_ε] at hst\n  specialize hst |t - s| hstp\n  rw [abs_sub_comm] at hst\n  linarith only [hst]\n\ndef contAt (f : ℝ → ℝ) (x₀ : ℝ) : Prop :=\n  ∀ ε &gt; 0, ∃ δ &gt; 0, ∀ x, |x - x₀| &lt; δ → |f x - f x₀| &lt; ε\n\ndef cont (f : ℝ → ℝ) : Prop := ∀ x₀ : ℝ, contAt f x₀\ncontinuity of function composition\ndef contAt_comp {f g : ℝ → ℝ} {x₀ : ℝ} (hf : contAt f (g x₀)) (hg : contAt g x₀) :\n    contAt (f ∘ g) x₀ := by\n  intro ε hε\n  rcases hf ε hε with ⟨δf, hδf, hf⟩\n  rcases hg δf hδf with ⟨δg, hδg, hg⟩\n  use δg, hδg\n  intro x hx\n  simp only [Function.comp_apply]\n  specialize hg x hx\n  specialize hf (g x) hg\n  exact hf\n[EXR] continuity of function composition\ndef cont_comp {f g : ℝ → ℝ} (hf : cont f) (hg : cont g) : cont (f ∘ g) := by\n  intro x\n  exact contAt_comp (hf (g x)) (hg x)\n[EXR] continuity implies sequential continuity\ndef tendsTo_of_contAt {f : ℝ → ℝ} {x₀ : ℝ} (hf : contAt f x₀)\n    {a : ℕ → ℝ} (ha : TendsTo a x₀) : TendsTo (f ∘ a) (f x₀) := by\n  intro ε hε\n  rcases hf ε hε with ⟨δ, hδ, hδf⟩\n  specialize ha δ hδ\n  rcases ha with ⟨n₀, hn₀⟩\n  use n₀\n  intro n hn\n  specialize hn₀ n hn\n  specialize hδf (a n) hn₀\n  exact hδf\nThe uniform limit of a sequence of continuous functions is continuous.\ndef uconv (f : ℕ → ℝ → ℝ) (f₀ : ℝ → ℝ) : Prop :=\n  ∀ ε &gt; 0, ∃ N : ℕ, ∀ n ≥ N, ∀ x : ℝ, |f n x - f₀ x| &lt; ε\n\ntheorem cont_of_cont_of_uconv\n    (f : ℕ → ℝ → ℝ) (f_cont : ∀ n : ℕ, cont (f n))\n    (f₀ : ℝ → ℝ) (h_uconv : uconv f f₀) : cont f₀ := by\n  intro x₀ ε hε\n  rcases h_uconv (ε / 3) (by linarith only [hε]) with ⟨N, hN⟩\n  specialize hN N (by linarith)\n  rcases f_cont N x₀ (ε / 3) (by linarith only [hε]) with ⟨δ, hδ, hδf⟩\n  use δ, hδ\n  intro x hx\n  specialize hδf x hx\n  have hNx := hN x\n  have hNx₀ := hN x₀\n  -- brute force `linarith` argument\n  rw [abs_lt] at hNx hNx₀ hδf ⊢\n  constructor\n  all_goals linarith only [hNx, hNx₀, hδf]\nThe sequential definition of function continuity is equivalent to the epsilon-delta definition.\ndef contAt_seq (f : ℝ → ℝ) (x₀ : ℝ) : Prop :=\n  ∀ a : ℕ → ℝ, TendsTo a x₀ → TendsTo (f ∘ a) (f x₀)\n[TODO] I failed to solve it swiftly. You are welcome to optimize it!\ntheorem contAt_iff_seq (f : ℝ → ℝ) (x₀ : ℝ) :\n    contAt f x₀ ↔ contAt_seq f x₀ := by\n  constructor\n  · intro hf a ha\n    exact tendsTo_of_contAt hf ha\n  · contrapose\n    intro hnfcont hnfseq\n    unfold contAt at hnfcont\n    push_neg at hnfcont\n    -- construct a sequence `a n` tending to `x₀`\n    let a (n : ℕ) : ℝ := 1 / (n + 1)\n    have a_gt_zero (n : ℕ) : a n &gt; 0 := by simp [a]; linarith only\n    have a_TendsTo_zero : TendsTo a 0 := by\n      intro ε hε\n      use Nat.ceil (1 / ε) -- ceiling function\n      intro n hn\n      rw [Nat.ceil_le] at hn\n      simp\n      rw [abs_of_pos (a_gt_zero n)]\n      unfold a\n      rw [div_lt_comm₀ (by linarith only) hε]\n      linarith only [hn]\n    -- construct a diverging sequence `f x` with `x` tending to `x₀`\n    -- this requires us to extract `Type*` objects from an existence to form a function\n    -- may meet universe issues if done naively\n    -- we use `Classical.indefiniteDescription` here to extract such objects classically\n    rcases hnfcont with ⟨ε, hε, hnf⟩\n    let x_subtype (n : ℕ) := Classical.indefiniteDescription _ &lt;| hnf (a n) (a_gt_zero n)\n    let x (n : ℕ) : ℝ := (x_subtype n).val\n    have x_lt_a (n : ℕ) : |x n - x₀| &lt; a n := by\n      unfold x\n      exact (x_subtype n).property.left\n    have fx_diverge (n : ℕ) : |f (x n) - f x₀| ≥ ε := by\n      unfold x\n      exact (x_subtype n).property.right\n\n    have x_tendsTo_x₀ : TendsTo x x₀ := by\n      suffices TendsTo (fun n ↦ x n - x₀) 0 by\n        have h_add := tendsTo_add this (tendsTo_const x₀)\n        simp at h_add; exact h_add\n      refine tendsTo_sandwich (?_ : TendsTo (fun n ↦ -a n) 0) (?_ : TendsTo (fun n ↦ a n) 0) ?_ ?_\n      · haveI := tendsTo_neg a_TendsTo_zero\n        simp at this; exact this\n      · exact a_TendsTo_zero\n      all_goals\n        intro n\n        haveI := x_lt_a n\n        rw [abs_lt] at this\n        linarith only [this]\n    -- but it is said that all such sequences converge\n    haveI := hnfseq x x_tendsTo_x₀\n    rcases this ε hε with ⟨n₀, hn₀⟩\n    specialize hn₀ n₀ (by linarith only); simp at hn₀\n    specialize fx_diverge n₀\n    linarith only [hn₀, fx_diverge]",
    "crumbs": [
      "Mathematical Analysis"
    ]
  },
  {
    "objectID": "06-ineq.html",
    "href": "06-ineq.html",
    "title": "Inequality",
    "section": "",
    "text": "Inequality PartialOrder\nabs, min and max\nThe Art of Capturing Premises (TAOCP)\nWheelchair tactics",
    "crumbs": [
      "Inequality"
    ]
  },
  {
    "objectID": "06-ineq.html#basics",
    "href": "06-ineq.html#basics",
    "title": "Inequality",
    "section": "1.1 Basics",
    "text": "1.1 Basics\nInequality is determined by a partial order PartialOrder. A partial order is a relation with reflexivity, antisymmetry, and transitivity. In Lean, a relation means α → α → Prop for some type α, capturing the fact that each a ≤ b gives a proposition.\nsection\n\nvariable (a b c d : ℚ)\nPartialOrder makes LE(≤) and LT(&lt;) available in the context.\n#check PartialOrder\n\n#check a ≤ b\n#check a &lt; b\n#check b ≥ a\n#check b &gt; a\n\n#check le_refl\n#check le_antisymm\n#check le_trans\n\n#check lt_irrefl\n#check lt_asymm\n#check lt_trans\n&lt; is determined by ≤\n#check lt_iff_le_not_ge\n≥, &gt; are just aliases of ≤, &lt;\nexample : (a &lt; b) = (b &gt; a) := by rfl\nexample : (a ≤ b) = (b ≥ a) := by rfl\n\nexample : a &lt; b ↔ a ≤ b ∧ a ≠ b := by\n  rw [lt_iff_le_not_ge]\n  constructor\n  · intro ⟨hab, hnba⟩\n    constructor\n    · exact hab\n    · intro h\n      rw [h] at hnba\n      apply hnba\n      exact le_refl b\n  · intro ⟨hab, hnab⟩\n    constructor\n    · exact hab\n    · intro hba\n      apply hnab\n      exact le_antisymm hab hba\n#check lt_of_le_of_ne -- this have a related theorem\nA linearly ordered commutative ring is a commutative ring with a total order s.t addition and multiplication are strictly monotone, e.g. ℚ.\nIn Lean this reads [CommRing R] [LinearOrder R] [IsStrictOrderedRing R].\nWe will work with ℚ as an example afterwards.\n[TODO] For some reason, LinearOrder ℚ is constructed using classical logic. Don’t be surprised if #print axioms ... shows some classical axioms.",
    "crumbs": [
      "Inequality"
    ]
  },
  {
    "objectID": "06-ineq.html#pure-partial-order-reasoning",
    "href": "06-ineq.html#pure-partial-order-reasoning",
    "title": "Inequality",
    "section": "1.2 Pure partial order reasoning",
    "text": "1.2 Pure partial order reasoning\nnorm_num tactic solves numerical equalities and inequalities automatically.\n#help tactic norm_num\nexample : (22 / 7 : ℚ) &lt; 4 := by norm_num\n\n-- [EXR]\nexample (hab : a ≤ b) (hba : b ≤ a) : a = b := by\n  apply le_antisymm\n  · exact hab\n  · exact hba\ngrw rewrites like rw, but works for inequalities.\n#help tactic grw\nexample (hab : a ≤ b) (hbc : b &lt; c) : a &lt; c := by\n  grw [hab]\n  exact hbc\nexample (hab : a ≤ b) (hbc : b &lt; c) : a &lt; c := by\n  grw [← hab] at hbc\n  exact hbc\n#check lt_of_le_of_lt -- this have a name\ncalc is a term / tactic for proving inequalities by chaining.\n#help tactic calc\nexample (hab : a ≤ b) (hbc : b &lt; c) : a &lt; c := by\n  calc\n    a ≤ b := hab\n    _ &lt; c := hbc",
    "crumbs": [
      "Inequality"
    ]
  },
  {
    "objectID": "06-ineq.html#linear-order-reasoning",
    "href": "06-ineq.html#linear-order-reasoning",
    "title": "Inequality",
    "section": "1.3 Linear order reasoning",
    "text": "1.3 Linear order reasoning\nA linear order is a partial order with le_total: either a ≤ b or b ≤ a.\n#check le_total\n[EXR] Use this to prove the trichotomy of &lt; and =.\nexample : a &lt; b ∨ a = b ∨ a &gt; b := by\n  rcases le_total a b with (hle | h)\n  · by_cases heq : a = b\n    · right; left; exact heq\n    · left\n      apply lt_of_le_of_ne\n      · exact hle\n      · exact heq\n  · -- do it similarly\n    sorry\n#check eq_or_lt_of_le -- this have a name",
    "crumbs": [
      "Inequality"
    ]
  },
  {
    "objectID": "06-ineq.html#monotonicity-of",
    "href": "06-ineq.html#monotonicity-of",
    "title": "Inequality",
    "section": "1.6 Monotonicity of *",
    "text": "1.6 Monotonicity of *\n[TODO] It’s not needed in the course so far, so we skip it for now.\nend",
    "crumbs": [
      "Inequality"
    ]
  },
  {
    "objectID": "06-ineq.html#automation",
    "href": "06-ineq.html#automation",
    "title": "Inequality",
    "section": "1.5 Automation",
    "text": "1.5 Automation\nTired of these? Use automation!\n\nlinarith\nlinarith is a powerful tactic that solves linear inequalities automatically. It uses hypotheses in the context and basic properties of linear orders to deduce the goal.\nlinarith only [h1, h2, ...] use only hypotheses h1, h2, … to solve the goal.\n#help tactic linarith\n\nexample : a &lt; b ↔ a - c &lt; b - c := by\n  constructor\n  all_goals\n    intro\n    linarith\n\nexample (h : a + b &lt; c + d) : a - d &lt; c - b := by\n  linarith\n\nexample (h : a &gt; 0) : (2 / 3) * a &gt; 0 := by\n  linarith\n\nexample (h : (-5 / 3) * a &gt; 0) : 4 * a &lt; 0 := by\n  linarith\nNote the limitations of linarith.\nIt only works for linear inequalities, not polynomial ones.\nexample : a ^ 2 ≥ 0 := by sorry -- linarith fails here\nthough some of polynomial inequalities can be solved by nlinarith\n#help tactic nlinarith\nexample : a ^ 2 ≥ 0 := by nlinarith\n#check sq_nonneg -- this have a name\nIt solve all inequalities in a dense linear order.\nIt does solve some inequalities in discrete linear orders like ℤ, but no guarantee for all of them.\nexample (n m : ℤ) (h : n &lt; m) : n + 1 ≤ m := by linarith\nexample (n m : ℤ) (h : n &lt; m) : n + (1/2 : ℚ) ≤ m := by sorry -- linarith fails here\nIt won’t recognize inequalities involving min, max, abs, etc. It won’t recognize some basic simp transformations, either.\nexample (h : a * (min 1 2) &gt; 0) : (id a) ≥ 0 := by\n  simp at *\n  linarith -- direct `linarith` will fail\n[EXR] ℚ admits a dense linear order\nexample (hab : a &lt; b) : ∃ c : ℚ, a &lt; c ∧ c &lt; b := by\n  use (a + b) / 2\n  constructor\n  all_goals linarith\n\n\nsimp\nadd_lt_add_iff_right-like theorems are registered for simp, so sometimes simp can reduce things like:\nexample (h : a + b &lt; c + b) : a &lt; c := by\n  simp at h\n  exact h\n\n\napply_fun\nSometimes you would like to apply_fun at an inequality. This requires you to manually show the monotonicity of the function.\nexample (h : a + b &lt; c + d) : a - d &lt; c - b := by\n  apply_fun (· - b - d) at h\n  · ring_nf at *\n    exact h\n  · unfold StrictMono\n    simp\n[EXR] Mimick the above example.\nexample (h : a + c ≤ b) : a ≤ b - c := by\n  apply_fun (· - c) at h\n  · ring_nf at *\n    exact h\n  · unfold Monotone\n    simp",
    "crumbs": [
      "Inequality"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "README",
    "section": "",
    "text": "This book / repository contains the lecture notes and supplementary materials for the hobby course “Introduction to Formal Mathematics with Lean 4”, offered in Fall 2025 at Beijing Institute of Technology.\nIt is best to download the repository and read it alongside a Lean 4 environment, so that you can try out the code examples and exercises interactively. We maintain an online version of the lecture notes with embedded Lean code if you prefer to read it in your browser. A printed PDF version is also provided as a souvenir, though no special effort has been made to resolve the hyperlinks.\n\nPortals\n\nCourse repository: https://github.com/sun123zxy/2025fall-lean4-teach\nOnline lecture notes: https://sun123zxy.github.io/2025fall-lean4-teach/\nOnline compiler: https://live.lean-lang.org\nCommunity (Lean Zulip): https://leanprover.zulipchat.com/\nLean 4 tactics cheatsheet: https://leanprover-community.github.io/papers/lean-tactics.pdf\n\n\n\nInstallation\nFirst make sure you have installed Git, VSCode and Lean 4 extension for VSCode correctly. Then execute the following commands in your terminal:\ngit clone git@github.com:sun123zxy/2025fall-lean4-teach.git\ncd 2025fall-lean4-teach\nlake exe cache get\nTo update the repository, make sure you have discarded any local changes (otherwise you may need to merge manually). Then execute the following commands in your terminal:\ngit pull\n\n\nCompiling the Book\nBoth the online and the PDF version of this book are generated by \\(\\SunQuarTeX\\), a publishing system based on Quarto and LaTeX. Refer to https://github.com/sun123zxy/sunquartex for more information.\n\n\nReferences\nWe recommend the following resources for further study of Lean and formalized mathematics.\nIntroductory videos and articles:\n\nCAV2024: https://leodemoura.github.io/files/CAV2024.pdf\nTerence Tao at IMO 2024: AI and Mathematics: https://www.youtube.com/watch?v=e049IoFBnLA\nLean 的前世今生: https://zhuanlan.zhihu.com/p/183902909\nNatural Number Game: https://adam.math.hhu.de/#/g/leanprover-community/nng4\nComputational Trilogy - nLab: https://ncatlab.org/nlab/show/computational+trilogy\n\nBibles for further study:\n\nMathematics in Lean (MIL): https://leanprover-community.github.io/mathematics_in_lean/\nA comprehensive tutorial for mathematicians to get started with Lean and the mathlib library. Focuses on building up mathematical structures.\nTheorem Proving in Lean 4: https://leanprover.github.io/theorem_proving_in_lean4/\nStrong emphasis on logic and dependent type theory. Excellent for both mathematicians and computer scientists.\nLean Language Manual: https://lean-lang.org/doc/reference/latest/\nComprehensive, precise description of Lean: a reference work in which Lean users can look up detailed information, rather than a tutorial intended for new users.\nType Theory - nLab: https://ncatlab.org/nlab/show/type+theory\nIf you want to understand the theoretical foundations of Lean, this is a good place to start.\nOther bibles: https://lakesare.brick.do/all-lean-books-and-where-to-find-them-x2nYwjM3AwBQ\n\nCourses and lecture notes:\n\nKevin Buzzard’s 2024 course on formalising mathematics in the Lean theorem prover: https://github.com/ImperialCollegeLondon/formalising-mathematics-2024"
  },
  {
    "objectID": "05-type.html",
    "href": "05-type.html",
    "title": "Type and Equality",
    "section": "",
    "text": "In the previous chapter, we have seen that propositions are types in the Prop universe. In this chapter, we shall move up to the Type* universe, and see how the most fundamental notion in mathematics, equality, works there.",
    "crumbs": [
      "Type and Equality"
    ]
  },
  {
    "objectID": "05-type.html#remark",
    "href": "05-type.html#remark",
    "title": "Type and Equality",
    "section": "2.1 Remark",
    "text": "2.1 Remark\nTwo questions arise naturally here:\n\nWhy Prop is separated from Type?\nThis is answered by the need of proof irrelevance.\nWhy Prop is at the bottom of the hierarchy?\nWe come up with two explanations ([TODO] discussions are welcome!):\n\nProp is often compared to Bool : Type. This analogy validates the Prop : Type convention.\nBool has two values true and false, representing truth values, acting as a switch. Prop may be viewed as a non-computatble version of Bool, switching by whether a proposition is true or false. e.g. In Mathlib, a subset of α is defined as a predicate α → Prop, a relation on α is defined as α → α → Prop, etc. But all of these are non-computable. e.g. you cannot define a computable function by this switch.\nOn determining universe levels of predicates and functions.\nFor a function α → β where α : Type u and β : Type v, its should live in Type (max u v) naturally. But recall ∀ and ∃ quantifiers from logic. They eat α → Prop functions to produce propositions, living in Prop. This means that Prop should be larger than any Type u to accommodate such functions. As a convention, we put Prop at the bottom of the hierarchy to reflect this. The true universe level of a function is imax u v if it maps from Sort u to Sort v, where imax is the regular max except that imax u 0 = imax 0 u = 0 for any u.",
    "crumbs": [
      "Type and Equality"
    ]
  },
  {
    "objectID": "05-type.html#handling-equality",
    "href": "05-type.html#handling-equality",
    "title": "Type and Equality",
    "section": "3.1 Handling equality",
    "text": "3.1 Handling equality\nvariable (a b c : ℚ)\nThe most basic way to show an equality is by tactic rfl: LHS is definitionally equal to RHS.\nexample : a = a := rfl\nNote that rfl works for not only literally-the-same terms, but also definitionally equal terms. We’ll detail definitional equality afterwards.\nrw is a tactic that rewrites a goal by a given equality.\nexample (f : ℚ → ℚ) (hab : a = b) (hbc : b = c) : f a = f c := by\n  rw [hab, hbc]\nyou may also apply the equality in the reverse direction\nexample (f : ℚ → ℚ) (hab : b = a) (hbc : b = c) : f a = f c := by\n  rw [← hab, hbc]\nYou may also use symm tactic to swap an equality\n#help tactic symm\nexample (f : ℚ → ℚ) (hab : b = a) (hbc : b = c) : f a = f c := by\n  symm at hab\n  rw [hab, hbc]\nor swap at the goal\nexample (f : ℚ → ℚ) (hab : b = a) : f a = f b := by\n  symm\n  rw [hab]\nYou may also rewrite at a hypothesis.\nexample (hab : a = b) (hbc : b = c) : a = c := by\n  rw [hbc] at hab\n  exact hab\ncongr tactic reduces the goal f a = f b to a = b.\n#help tactic congr\nexample (f : ℚ → ℚ) (hab : a = b) (hbc : b = c) : f a = f c := by\n  congr\n  rw [hab, hbc]",
    "crumbs": [
      "Type and Equality"
    ]
  },
  {
    "objectID": "05-type.html#working-in-commring",
    "href": "05-type.html#working-in-commring",
    "title": "Type and Equality",
    "section": "3.2 Working in CommRing",
    "text": "3.2 Working in CommRing\nLet’s do some basic rewrites in commutative rings, e.g. ℚ.\n\nCommutativity and associativity\n#check add_comm\nexample : a + b = b + a := by rw [add_comm]\n\n#check add_assoc\nexample : (a + b) + c = a + (b + c) := by rw [add_assoc]\n\n#check mul_comm\nexample : a * b = b * a := by rw [mul_comm]\n\n#check mul_assoc\nexample : (a * b) * c = a * (b * c) := by rw [mul_assoc]\nSometimes you need to specify the arguments to narrow down possible targets for rw.\nexample : (a + b) + c = (b + a) + c := by\n  rw [add_comm a b]\n[EXR] You may chain multiple rewrites in one rw.\nexample : (a + b) + c = a + (c + b) := by\n  rw [add_assoc, add_comm b c]\n\n-- [EXR]\nexample : a + b + c = c + a + b := by\n  rw [add_comm, add_assoc]\n\n#check mul_add\nexample : (a + b) * c = c * a + c * b := by\n  rw [mul_comm, mul_add]\n\n-- [EXR]\nexample : (a + b) * (c + b) = a * c + a * b + b * c + b * b := by\n  rw [add_mul, mul_add, mul_add, ← add_assoc]\n\n\nZero and one\n#check add_zero\nexample : a + 0 = a := by rw [add_zero]\n#check zero_add\nexample : 0 + a = a := by rw [zero_add]\n\n#check mul_one\nexample : a * 1 = a := by rw [mul_one]\n#check one_mul\nexample : 1 * a = a := by rw [one_mul]\n\n-- [EXR]\nexample : 1 * a + (0 + b) * 1 = a + b := by\n   rw [one_mul, zero_add, mul_one]\n[EXR] uniqueness of zero\nexample (o : ℚ) (h : ∀ x : ℚ, x + o = x) : o = 0 := by\n  specialize h 0\n  rw [zero_add] at h\n  exact h\n\n\nSubtraction\ntransposition\n#check add_sub_assoc\n#check sub_self\n#check add_zero\nexample (h : c = a + b) : c - b = a := by\n  rw [h, add_sub_assoc, sub_self, add_zero]\n\n\nAutomation\nHad enough of these tedious rewrites? Automation makes your life easier.\nsimp (at h) tactic eliminates 0 and 1 automatically. simp? shows you what lemmas simp used.\n#help tactic simp\nexample : c + a * (b + 0) = a * b + c := by\n  simp\n  rw [add_comm]\nring tactic is even stronger: it reduces LHS and RHS to a canonical form (it exists in any commutative ring) to solve equalities automatically. ring_nf (at h) reduces the expression h to its canonical form.\n#help tactic ring -- check out the documentation\nexample : (a + 1) * (b + 2) = a * b + 2 * a + b + 2 := by\n  ring\napply_fun at h tactic applies a function to both sides of an equality hypothesis h. Combined with simp and ring, it make transpotions easier.\n#help tactic apply_fun\nexample (h : a + c = b + c) : a = b := by\n  apply_fun (fun x ↦ x - c) at h\n  simp at h\n  exact h\n[EXR] transposition again\nexample (h : c = a + b) : c - b = a := by\n  apply_fun (fun x ↦ x - b) at h\n  simp at h\n  exact h\n\n\nA remark on type classes\nWondering how Lean knows that commutativity, associativity, distributivity, etc. hold for ℚ? Wondering how Lean knows a * 1 = a and has relevant lemmas for that? This is because Lean knows that ℚ is an commutative ring. This is because in Mathlib, ℚ has been registered as an instance of the typeclass CommRing. So that once you import Mathlib, Lean automatically knows about the CommRing structure of ℚ. We might learn about typeclasses later in this course.\n#synth CommRing ℚ -- Checkout the `CommRing` instance that Mathlib provides for `ℚ`",
    "crumbs": [
      "Type and Equality"
    ]
  },
  {
    "objectID": "05-type.html#funext-and-propext",
    "href": "05-type.html#funext-and-propext",
    "title": "Type and Equality",
    "section": "3.3 funext and propext",
    "text": "3.3 funext and propext\nThere are several ways to show a (propositional) equality other than rfl and rw.\nFunctional extensionality funext states that two functions are equal if they give equal outputs for every input.\nIt’s a theorem in Lean’s type theory, derived from the quotient axiom Quot.sound.\n#check funext\nexample (f g : ℚ → ℚ) (h : ∀ x : ℚ, f x = g x) : f = g := funext h\nIt has a tactic version ext / funext as well\n#help tactic funext\nexample (f g : ℚ → ℚ) (h : ∀ x : ℚ, f x = g x) : f = g := by\n  funext x\n  exact h x\nPropositional extensionality propext states that two propositions are equal if they are logically equivalent. It’s admitted as an axiom in Lean.\n#check propext\nexample (P Q : Prop) (h : P ↔ Q) : P = Q := propext h\nIt has a tactic version ext as well\n#help tactic ext\nexample (P Q : Prop) (h : P ↔ Q) : P = Q := by\n  ext\n  exact h\nThis allows you to rw an iff (↔︎) like an equality (=).\nexample (P Q : Prop) (h : P ↔ Q) : P = Q := by\n  rw [h]",
    "crumbs": [
      "Type and Equality"
    ]
  },
  {
    "objectID": "05-type.html#global-definitions",
    "href": "05-type.html#global-definitions",
    "title": "Type and Equality",
    "section": "4.1 Global definitions",
    "text": "4.1 Global definitions\nRecall that you may use def to define your own terms.\ndef myNumber : ℚ := 998244353\n#check myNumber\ndef can also define functions.\n#check fun (x : ℚ) ↦ x * x\ndef square (x : ℚ) : ℚ := x * x\ndef square' : ℚ → ℚ := fun x ↦ x * x\n#print square\n#print square'\nBe open minded: you may even use tactic mode to define terms!\ndef square'' : ℚ → ℚ := by\n  intro x\n  exact x * x\n#print square''\n\ndef square_myNumber : ℚ := by\n  apply square\n  exact myNumber\n#print square_myNumber",
    "crumbs": [
      "Type and Equality"
    ]
  },
  {
    "objectID": "05-type.html#local-definitions",
    "href": "05-type.html#local-definitions",
    "title": "Type and Equality",
    "section": "4.2 Local definitions",
    "text": "4.2 Local definitions\nYou may also define local terms and functions using let. It may be used in both term mode and tactic mode.\n#help tactic let\n\nexample : ℚ := by\n  let a : ℚ := 3\n  let b : ℚ := 4\n  exact square (a + b)\n\nexample : ℚ :=\n  let a : ℚ := 3\n  let b : ℚ := 4\n  square (a + b)\n\nexample : let a := 4; let b := 4; a = b := rfl\nSometimes you want an alias for a complex term. set tactic is a variant of let that automatically replaces all occurrences of the defined term.\n#help tactic set\n\nexample (a b c : ℕ) : 0 = a + b - (a + b) := by\n  set d := a + b\n  simp\nIt’s crucial to distinguish between let and have: let saves the term of the definition for later use, but have is “opaque”: it won’t let you unfold the definition later. Thus naturally, let is often used for Type*s, and have is used for Props.\nexample : 3 = 3 := by\n  let a := 3\n  let b := 3\n  have h : a = b := rfl\n  exact h\n\nexample : 3 = 3 := by\n  have a := 3\n  have b := 3\n  -- have h : a = b := rfl\n  sorry -- above won't compile\n[TODO] Explain why it works here.\nexample : have a := 3; have b := 3; a = b := rfl",
    "crumbs": [
      "Type and Equality"
    ]
  },
  {
    "objectID": "05-type.html#unfolding-definitions",
    "href": "05-type.html#unfolding-definitions",
    "title": "Type and Equality",
    "section": "4.3 Unfolding definitions",
    "text": "4.3 Unfolding definitions\nTo manually unfold a definition in the tactic mode, you may use the rw (at h) tactic or the unfold (at h) tactic.\n#help tactic unfold\nexample : square myNumber = 998244353 * 998244353 := by\n  rw [square]\n  unfold myNumber\n  rfl\nFor local (non-have) definitions, you may use unfold as well. Though sadly rw does not work for local definitions for now.\nexample (a b : ℕ): (a + b) - (a + b) = 0 := by\n  set d := a + b\n  unfold d\n  simp\nLuckily, have, let and set all allows you to obtain a propositional equality when defining. (Technically this is not an unfolding, though.)\nexample (a b : ℕ) : (a + b) - (a + b) = 0 := by\n  let (eq := h1) d1 := a + b\n  have (eq := h2) d2 := a + b\n  set d3 := a + b with h3\n  simp",
    "crumbs": [
      "Type and Equality"
    ]
  },
  {
    "objectID": "05-type.html#definitional-equality-vs-propositional-equality",
    "href": "05-type.html#definitional-equality-vs-propositional-equality",
    "title": "Type and Equality",
    "section": "4.4 Definitional equality vs propositional equality",
    "text": "4.4 Definitional equality vs propositional equality\n[IGNORE] Skip this if you find it confusing for the first time. You can recall this when we deal with quotient types.\nDefinitional equality means that two terms are the same by definition (i.e. they reduce to the same form).\n\ndef, theorem-like commands\nApplications of functions\n\nare examples of definitional equalities.\nIt is a meta-level concept, it cannot be stated as a proposition.\n\nrfl\nAs the sole constructor of propositional equality, rfl proves a definitional equality.\n#check rfl\nNote that myNumber is definitionally equal to 998244353.\nexample : myNumber = 998244353 := rfl\nrfl can even solve simple evaluations, because both sides reduce to 8 by the (inductive) definition of arithmetic operations over ℕ.\nexample : 5 + 3 = 2 * 2 * 2 := rfl\nrfl also has a tactic version. This tactic works for logical equivalences (↔︎) as well, as Iff.rfl does.\n#help tactic rfl\n\nexample : True ↔ True := by rfl\nThese are some non-examples for definitional equality. They are only propositionally equal, by propext and logical equivalence.\n-- example (p : Prop) : True ↔ (p → True) := by rfl\n-- example True ↔ ¬ False := by rfl\n\n\nType checking\nType checking is determined up to definitional equality.\nIn fact, it’s the sole responsibility of Lean’s compiler to check definitional equalities.\nAn failure of definitional equality results in a type error. That is, it is regarded as invalid Lean code.\ndef myType := ℚ\nThis won’t compile, because Lean do not know a coercion of ℕ → myType.\n-- def myTypeNumber := (998244353 : myType)\nThis passes the type check. because we manually build a bridge here: Lean knows the coercion ℕ → ℚ and that myType is definitionally equal to ℚ.\ndef myTypeNumber : myType := (998244353 : ℚ)\n#check myTypeNumber\nThis also passes the type check for the same reason.\n#check myTypeNumber = myNumber\nThe type of myNumber : ℚ and myTypeNumber : myType are definitionally equal, thus the equality passes the type check. Their values are also definitionally equal, so you can prove their equality by rfl.\nexample : myTypeNumber = myNumber := rfl\nabbrev defines an abbreviation, which is like a def, but always expands when processed. This is useful for type synonyms.\nabbrev myAbbrev := ℚ\ndef myAbbrevNumber : myAbbrev := 998244353\n#check myAbbrevNumber\n\n\nPropositional equality\nPropositional equality is\n\ndefined as the inductive type Eq (notation =),\nconstructed by the constructor rfl (reflexivity, i.e. a = a), with propext and Quot.sound as extra axioms (funext is an corollary of Quot.sound),\neliminated by the rw tactic (in practice).\n\nPropositional equality is not a meta-level concept. It’s a proposition in Prop that may be proved or disproved.\nPropositional equality on types does not get the types check. For example, this won’t compile.\n-- example (α : Type) (h : α = ℕ) (a : α) : a = (998244353 : ℕ) := by sorry\n\nend",
    "crumbs": [
      "Type and Equality"
    ]
  },
  {
    "objectID": "poster.html",
    "href": "poster.html",
    "title": "形式化数学与 Lean 4 定理证明入门",
    "section": "",
    "text": "背景简介\n形式化数学是将数学定义、定理和证明转化为计算机可验证的精确形式的过程。可以认为，数学形式化 = 编写程序，而正确的证明 = 代码通过编译。严谨性是数学研究的基石，形式化数学通过严格的逻辑框架和程序语言确保数学结论的正确性和可复用性，在现代数学体系日渐庞大复杂的背景下具有重要意义。\nLean 4 是一个专为形式化数学设计的编程语言和证明助手，支持数学家将数学定理转化为计算机可验证的代码。它具备高效的编译器和灵活的类型系统，适合构建复杂的数学证明；其数学库 Mathlib 正在飞速扩展，目前已覆盖本科数学大部分内容。Lean 4 已成为目前数学形式化工作的主流选择。\nAI4Math 是将人工智能技术应用于数学研究的跨学科领域。其目标是通过机器学习、大语言模型等方法，简化形式化过程中的繁重代码编写工作，辅助数学家进行数学形式化、定理证明乃至提出猜想。AI4Math 或将在将来大幅提高数学形式化和数学研究的效率。\n\n\n课程信息\n本兴趣课程旨在向数学或计算机相关专业学生普及形式化数学的基本概念和方法，掌握 Lean 4 定理证明的基本技能，并了解 AI4Math 的最新进展，为后续更深入的探索做好引导。课程设计为 2025 秋季学期范洋宇老师《抽象代数》的配套课余活动，欢迎感兴趣的同学参与。\n本课程原则上不要求任何编程或数学背景，但建议具备至少一侧的常识。我们建议有意动手实操的同学携带电脑，并提前配置好网络、Git、VSCode 等相关环境。\n\n\n\n时间：1–12 周周三 18:30–20:05\n地点：文萃楼 F502\n主讲人：钟星宇\n\n\n北京理工大学 2022 级强基数学专业本科生\nMathlib 4 Contributor\nICPC Regional Silver Medalist\n2025 BICMR–RUC 代数与形式化暑期学校学员\nBICMR–Ubiquant AI4Math 数据标注团队实习经验\n\n\n\n\n\n\n课程大纲\nMain topics:\n\nIntroduction to Formal Mathematics with Lean 4\nLogic and Proofs\nThe Type Universe and Equality\nInequalities\nMathematical Analysis: Taking Limits on the Real Numbers\nAbstract Algebra: Groups and Homomorphisms\nSubstructures and Subgroups\nQuotient Types and Quotient Groups\n\nIf time permits:\n\nInductive Types and Induction Methods\nClasses and Instances\nCoercions\n\n\n\n参考材料\n\nIntroductory:\n\nCAV2024\nTerence Tao at IMO 2024: AI and Mathematics\nLean 的前世今生\nNatural Number Game\nComputational Trilogy - nLab\n\nBibles\n\nMathematics in Lean 4\nTheorem Proving in Lean 4\nLean Language Manual\nType Theory - nLab\nOther bibles\n\nCourses\n\nKevin Buzzard’s 2024 course on formalising mathematics in the Lean theorem prover\n\n\n\n\n\n链接\n\nCourse materials:\n\ncourse repository\nonline documentation\n\nOnline compiler:\n\nLean 4 Web\n\nCommunity\n\nLean Zulip\n\nMiscellaneous\n\nLean 4 tactics cheatsheet",
    "crumbs": [
      "形式化数学与 Lean 4 定理证明入门"
    ]
  },
  {
    "objectID": "04-logic.html",
    "href": "04-logic.html",
    "title": "Logic (Part III)",
    "section": "",
    "text": "True, False and Not\nclassical logic tactics, e.g. proof by contradiction\nnegation-pushing techniques\nthe difference between classical and intuitionistic logic\nDecidable\n3 is recommended for those who wants to have some exercises. For lazy ones, you may only remember the tactics introduced there.\n4, 5 are optional and left for logical lunatics.",
    "crumbs": [
      "Logic (Part III)"
    ]
  },
  {
    "objectID": "04-logic.html#true",
    "href": "04-logic.html#true",
    "title": "Logic (Part III)",
    "section": "1.1 True (⊤)",
    "text": "1.1 True (⊤)\nTrue has a single constructor True.intro, which produces the unique proof of True. True is self-evidently true by True.intro.\n#check True.intro\nTrue as the terminal object\nexample : p → True := by\n  intro _\n  exact True.intro\nThe following examples shows that True → p is logically equivalent to p.\nexample (hp : p) : True → p := by\n  intro _\n  exact hp\n[IGNORE] Above is actually the elimination law of True.\nexample (hp : p) : True → p := True.rec hp\n\nexample (htp : True → p) : p := htp True.intro\ntrivial is a tactic that solves goals of type True using True.intro, though it’s power does not stop here.\nexample (htp : True → p) : p := by\n  apply htp\n  trivial",
    "crumbs": [
      "Logic (Part III)"
    ]
  },
  {
    "objectID": "04-logic.html#false",
    "href": "04-logic.html#false",
    "title": "Logic (Part III)",
    "section": "1.2 False (⊥)",
    "text": "1.2 False (⊥)\nFalse has no constructors, meaning that there is no way to construct a proof of False. This means that False is always false.\nFalse.elim is the eliminator of False, serve as the “principle of explosion”, which allows us to derive anything from a falsehood. False.elim is self-evidently true in Lean’s dependent type theory.\n#check False.elim\n#check False.rec -- [IGNORE] `False.elim` is actually defined as `False.rec`\neliminating False\nexample (hf : False) : p := False.elim hf\nexfalso is a tactic that applys False.elim to the current goal, changing it to False.\nexample (hf : False) : p := by\n  exfalso\n  exact hf\ncontradiction is a tactic that proves the current goal by finding a trivial contradiction in the context.\nexample (hf : False) : p := by\n  contradiction\n\n-- [EXR]\nexample (h : 1 + 1 = 3) : RiemannHypothesis := by\n  contradiction\nOn how to actually obtain a proof of False from a trivially false hypothesis via term-style proof [TODO], see here\n[IGNORE] Experienced audiences may question why False.elim lands in Sort* universe instead of Prop. This is because False is a subsingleton. See the manual to understand how the universe of a recursor is determined.\nend",
    "crumbs": [
      "Logic (Part III)"
    ]
  },
  {
    "objectID": "04-logic.html#negation-with-and",
    "href": "04-logic.html#negation-with-and",
    "title": "Logic (Part III)",
    "section": "3.1 Negation with ∧ and ∨",
    "text": "3.1 Negation with ∧ and ∨\nsection\n\nvariable (p q r : Prop)\nClassical logic: case analysis\nexample (hpq : p → q) (hnpq : ¬p → q) : q := Or.elim (Classical.em p) hpq hnpq\n#check Classical.byCases -- above has a name\nWe have a corresponding tactic: by_cases\nexample (hpq : p → q) (hnpq : ¬p → q) : q := by\n  by_cases hp : p\n  · exact hpq hp\n  · exact hnpq hp\nProof by cases would help us to obtain an equivalent characterization of Or.\nexample : (p ∨ q) ↔ (¬p → q) := by\n  constructor\n  · rintro (hp | hq)\n    · intro hnp\n      exfalso\n      exact hnp hp\n    · intro _\n      exact hq\n  · intro hnpq  -- the direction of constructing `Or` needs classical logic\n    by_cases h?p : p\n    · left; exact h?p\n    · right; exact hnpq h?p\nNote that this vividly illustrates the difference between classical logic and intuitionistic logic.\nIn intuitionistic logic, Or means slightly stronger than in classical logic: by p ∨ q we mean that we know explicitly which one of p and q is true. We cannot do implications like ¬p → q implying p ∨ q, because we don’t know exactly which one of p and ¬p is true, and the introduction rules of Or are asking us to provide it explicitly. This is a reason why intuitionistic logic is considered to be computable.\nWe also have an equivalent characterization of And. This is also done in classical logic.\nexample : (p ∧ q) ↔ ¬(p → ¬q) := by\n  constructor\n  · intro ⟨hp, hnq⟩ hpnq\n    exact hpnq hp hnq\n  · intro hnpnq -- the direction of constructing `And` needs classical logic\n    contrapose hnpnq\n    rw [Classical.not_not]\n    intro hp hq\n    exact hnpnq ⟨hp, hq⟩\n[EXR] →–∨ distribution\nexample : (r → p ∨ q) ↔ ((r → p) ∨ (r → q)) := by\n  constructor\n  · intro hrpq -- this direction needs classical logic\n    by_cases h?r : r\n    · rcases hrpq h?r with (hp | hq)\n      · left; intro _; exact hp\n      · right; intro _; exact hq\n    · left\n      intro hr\n      exfalso; exact h?r hr\n  · rintro (hrp | hrq)\n    · intro hr\n      left; exact hrp hr\n    · intro hr\n      right; exact hrq hr\n#check imp_or -- above has a name\n[EXR] De Morgan’s laws\nexample : ¬(p ∨ q) ↔ ¬p ∧ ¬q := by\n  constructor\n  · intro hnq\n    constructor\n    · intro hp\n      apply hnq\n      left; exact hp\n    · intro hq\n      apply hnq\n      right\n      exact hq\n  · rintro ⟨hnp, hnq⟩ (hp | hq)\n    · exact hnp hp\n    · exact hnq hq\n#check not_or -- above has a name\n[EXR] De Morgan’s laws\nexample : ¬(p ∧ q) ↔ ¬p ∨ ¬q := by\n  constructor\n  · intro hnpq -- this direction needs classical logic\n    by_cases h?p : p\n    · right\n      intro hq\n      apply hnpq\n      exact ⟨h?p, hq⟩\n    · left\n      exact h?p\n  · rintro (hnp | hnq) ⟨hp, hq⟩\n    · exact hnp hp\n    · exact hnq hq\n#check not_and -- above has a name\nIntroducing push_neg tactic: automatically proves all the above. It works in classical logic where negation normal forms exist.\nby_contra!, contrapose! are push_neg-enhanced version of their non-! counterparts.\nFor more exercises, see Propositions and Proofs - TPiL4\nend",
    "crumbs": [
      "Logic (Part III)"
    ]
  },
  {
    "objectID": "02-logic.html",
    "href": "02-logic.html",
    "title": "Logic (Part I)",
    "section": "",
    "text": "1 Implication →\nImplication → is the most fundamental way of constructing new types in Lean’s dependent type theory. It’s one of the first-class citizens in Lean.\nIn the universe of Prop, for propositions p and q, the implication p → q means “if p then q”.\nsection\n\nvariable (p q r : Prop) -- this introduces global variables within this section\n\n#check p\n#check q\n#check p → q\n→ is right-associative. In general, hover the mouse over the operators to see how they associate. so p → q → r means p → (q → r). You may notice that this is logically equivalent to p ∧ q → r. This relationship is known as currification. We shall discuss this later.\nmodus ponens\ntheorem mp : p → (p → q) → q := by sorry -- `sorry` is a placeholder for unfinished proofs\nBy the Curry–Howard correspondence, p → q is also understood as a function that takes a proof of p and produces a proof of q.\nWe introduce an important syntax to define functions / theorems: When we define a theorem theorem name (h1 : p1) ... (hn : pn) : q := ..., we are actually defining a function name of type (h1 : p1) → ... → (hn : pn) → q. Programmingly, h1, …, hn are the parameters of the function and q is the return type.\nThe significance of this syntax, compared to theorem name : p1 → ... → pn → q := ..., is that now h1, …, hn, proofs of p1, …, pn, are now introduced as hypotheses into the context, available for you along the way to prove q.\nthis proves a theorem of type p → p\nexample (hp : p) : p := hp\nmodus ponens, with a proof\nexample (hp : p) (hpq : p → q) : q := hpq hp\nA function can also be defined inline, using fun (lambda syntax): fun (h1 : p1) ... (hn : pn) ↦ (hq : q) defines a function of type (h1 : p1) → ... → (hn : pn) → q\nSome of the type specifications may be omitted, as Lean can infer them.\nexample : p → p := fun (hp : p) ↦ (hp : p)\nexample : p → p := fun (hp : p) ↦ hp\nexample : p → (p → q) → q := fun (hp : p) (hpq : p → q) ↦ hpq hp\nexample : p → (p → q) → q := fun hp hpq ↦ hpq hp\n\n\n2 Tactic Mode\nConstruct proofs using explicit terms is called term-style proof. This can be tedious for complicated proofs.\nFortunately, Lean provides the tactic mode to help us construct proofs interactively.\nby activates the tactic mode.\nThe tactic mode captures the way mathematicians actually think: There is a goal q to prove, and we have several hypotheses h1 : p1, …, hn : pn in the context to use. We apply tactics to change the goal and the context until the goal is solved. This produces a proof of p1 → ... → pn → q.\nexample (hp : p) : p := by exact hp\ntactic: exact If the goal is p and we have hp : p, then exact hp solves the goal.\nexact? may help to close some trivial goals\nexample (hp : p) (hpq : p → q) : q := by exact?\ntactic: intro Sometimes a hypothesis is hidden in the goal in the form of an implication. If the goal is p → q, then intro hp changes the goal to q and adds the hypothesis hp : p into the context.\nmodus ponens, with a hidden hypothesis\nexample (hp : p) : (p → q) → q := by\n  intro hpq\n  exact hpq hp\n\nexample (hq : q) : p → q := by\n  intro _  -- use `_` as a placeholder if the introduced hypothesis is not needed\n  exact hq\nmodus ponens, with two hidden hypothesis\nexample : p → (p → q) → q := by\n  intro hp hpq -- you can `intro` multiple hypotheses at once\n  exact hpq hp\n[EXR] transitivity of →\nexample : (p → q) → (q → r) → (p → r) := by\n  intro hpq hqr hp\n  exact hqr (hpq hp)\ntactic: apply If q is the goal and we have hpq : p → q, then apply hpq changes the goal to p.\nmodus ponens\nexample (hp : p) (hpq : p → q) : q := by\n  apply hpq\n  exact hp\n[EXR] transitivity of →\nexample (hpq : p → q) (hqr : q → r) : p → r := by\n  intro hp\n  apply hqr\n  apply hpq\n  exact hp\n[IGNORE] Above tactics are minimal and sufficient for simple proofs. When proofs went more complicated, you may want more tactics that suit your needs. Remember your favorite tactics and use them accordingly.\ntactic: specialize If we have hpq : p → q and hp : p, then specialize hpq hp reassigns hpq to hpq hp, a proof of q.\nexample (hp : p) (hpq : p → q) : q := by\n  specialize hpq hp\n  exact hpq\n\nexample (hpq : p → q) (hqr : q → r) : p → r := by\n  intro hp\n  specialize hpq hp\n  specialize hqr hpq\n  exact hqr\ntactic: have have helps you to state and prove a lemma in the middle of a proof. have h : p := hp adds the hypothesis h : p into the context, where hp is a proof of p that you provide.\nhaveI is similar to have, but it adds the hypothesis as this.\nexample (hpq : p → q) (hqr : q → r) : p → r := by\n  intro hp\n  have hq : q := hpq hp\n  have hr : r := by -- combine with `by` is also possible\n    apply hqr\n    exact hq\n  exact hr\ntactic: suffices Say our goal is q, suffices hp : p from hq changes the goal to p, as long as you can provide a proof hq of q from a proof hp of p. You may also switch to the tactic mode by suffices hp : p by ...\nexample (hpq : p → q) (hqr : q → r) : p → r := by\n  intro hp\n  suffices hq : q from hqr hq\n  exact hpq hp\n\nexample (hpq : p → q) (hqr : q → r) : p → r := by\n  intro hp\n  suffices hq : q by\n    apply hqr\n    exact hq\n  exact hpq hp\nshow (it is not a tactic!) Sometimes you want to clarify what exactly you are giving a proof for. show p from h make sure that h is interpreted as a proof of p. show p by ... switches to the tactic mode to construct a proof of p.\nexample (hpq : p → q) (hqr : q → r) : p → r := by\n  intro hp\n  exact hqr (show q by apply hpq; exact hp)\n\nend",
    "crumbs": [
      "Logic (Part I)"
    ]
  }
]